{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: This tutorial is in **FRENCH** only.*\n",
    "\n",
    "# Tutoriel Jules Vernes\n",
    "\n",
    "\n",
    "<img src=\"images/jules_verne_1.png\" style='float: left; width: 30%; margin:10%; margin-top:0%; margin-bottom:0%'><img src=\"images/jules_verne_2.png\" style='float: left; width: 30%; margin:10%; margin-top:0%; margin-bottom:0%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Pr√©-requis :**\n",
    "\n",
    "- Ce notebook doit avoir √©t√© g√©n√©r√© avec le template NLP du projet Gabarit.\n",
    "\n",
    "\n",
    "- T√©l√©charger le fichier `texts.csv` se trouvant ici (https://github.com/OSS-Pole-Emploi/AI_frameworks/tree/main/gabarit/template_nlp/nlp_data) et le placer dans le r√©pertoire `{{package_name}}-data` du package que vous avez g√©n√©r√©.\n",
    "\n",
    "\n",
    "- **Lancer ce notebook avec un kernel utilisant l'environnement virtuel de votre projet**. Pour ce faire, il suffit de faire : `python -m ipykernel install --user --name=your_venv_name` (une fois votre environnement virtuel activ√©). Evidemment, le projet g√©n√©r√© doit √™tre install√© sur cet environnement virtuel. Il peut √™tre n√©cessaire de rafra√Æchir votre navigateur pour voir le kernel appara√Ætre.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des mati√®res :\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "* [1. Objectifs](#objectifs)\n",
    "\n",
    "\n",
    "* [2. Principes](#principes)\n",
    "\n",
    "\n",
    "* [3. Entrainement d'un mod√®le de d√©tection d'auteurs 'out of the box'](#entrainement)\n",
    "\n",
    "\n",
    ">  * [3.1 Imports et fonctions utilitaires](#imports)\n",
    "\n",
    ">  * [3.2 Chargement des donn√©es](#data)\n",
    "\n",
    ">  * [3.3 Analyse rapide](#analyse)\n",
    "\n",
    ">  * [3.4 D√©coupage du jeu de donn√©es en train / test](#decoupage)\n",
    "\n",
    ">  * [3.5 Preprocessing sur les textes](#preprocessing)\n",
    "\n",
    ">  * [3.6. Entrainement d'un premier mod√®le](#model1)\n",
    "\n",
    ">  * [3.7. Pr√©dictions avec notre premier mod√®le](#predictions)\n",
    "\n",
    ">  * [3.8. Cr√©ation d'un second mod√®le \"maison\"](#maison)\n",
    ">>  * [3.8.1.  D√©coupage en phrases](#phrases)\n",
    ">>  * [3.8.2.  Cr√©ation d'une nouvelle classe de mod√®le](#new_class)\n",
    ">>  * [3.8.3.  Packaging de notre nouvelle classe mod√®le](#packaging)\n",
    ">>  * [3.8.4.  R√©utilisation de notre classe avec les scripts du projet](#scripting)\n",
    "\n",
    "* [4. It's showtime ](#showtime)\n",
    "\n",
    "\n",
    "* [5. Conclusion](#conclusion)\n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectifs <a class=\"anchor\" id=\"objectifs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- L'objectif principal de ce tutoriel est de vous introduire au projet Open Source `Gabarit`, d√©velopp√© par l‚Äô√©quipe IA de P√¥le Emploi.\n",
    "\n",
    "\n",
    "- Nous allons traiter un cas d'usage \"jouet\" : la d√©tection automatique de l'auteur d'un texte du XIX√®me si√®cle.\n",
    "\n",
    "\n",
    "- A la fin de ce tutoriel, nous esp√©rons vous donner tous les outils n√©cessaires pour d√©marrer rapidement un nouveau projet d'IA, propre et pr√™t √† √™tre industrialis√©.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Principes <a class=\"anchor\" id=\"principes\"></a>\n",
    "\n",
    "\n",
    "- Ce projet a √©t√© developp√© dans une logique d'acc√©l√©ration des d√©veloppements de nos projets IA, et dans l'objectif de fournir une base de code commune facilitant le passage en industrialisation de nos mod√®les.\n",
    "\n",
    "\n",
    "- Pour ce faire, nous proposons diff√©rents **templates** de projets IA :  \n",
    "<br>  \n",
    "<br>  \n",
    "    - Template NLP : classification de donn√©es textuelles  \n",
    "<br>  \n",
    "<br>  \n",
    "    \n",
    "    - Template NUM : classification et r√©gression sur des donn√©es num√©riques  \n",
    "<br>  \n",
    "<br>  \n",
    "    \n",
    "    - Template VISION : classification d'images et d√©tection d'objets  \n",
    "<br>  \n",
    "<br>  \n",
    "    \n",
    "    \n",
    "- L'id√©e n'est pas de cr√©er un outil cl√© en main 'low-code', mais bien de fournir une base de code que chaque Data Scientist pourra adapter √† son projet. Il aura ainsi le contr√¥le de tout ce qu'il s'y passe.\n",
    "\n",
    "\n",
    "- Les templates sont tr√®s similaires entre eux, m√™me s'ils ont √©videmment chacun leur sp√©cificit√©.  \n",
    "\n",
    "\n",
    "- Les projets g√©n√©r√©s sont compos√©s d'une partie 'package' et d'une partie 'scripts' qui permettent notamment de lancer les entrainements.  \n",
    "\n",
    "\n",
    "- Le projet est construit de mani√®re √† ce que tous les mod√®les soient '**agnostic**'. De cette mani√®re, on appelera un mod√®le toujours de la m√™me fa√ßon (e.g. model.predict(...)) peu importe qu'il s'agisse d'un mod√®le Sklearn ou TensorFlow.\n",
    "\n",
    "\n",
    "- Des d√©monstrateurs Streamlit sont int√©gr√©s aux projets pour pouvoir rapidement faire des pr√©sentations √† votre m√©tier !\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrainement d'un mod√®le de d√©tection d'auteurs 'out of the box' <a class=\"anchor\" id=\"entrainement\"></a>\n",
    "\n",
    "On va partir de textes de diff√©rents auteurs du XIX√®me si√®cle et fabriquer un mod√®le permettant **d'identifier automatiquement son auteur**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 Imports et fonctions utilitaires <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "from {{package_name}} import utils\n",
    "from {{package_name}}.preprocessing import preprocess\n",
    "from {{package_name}}.models_training import utils_models\n",
    "from {{package_name}}.models_training.model_tfidf_svm import ModelTfidfSvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 Chargement des donn√©es <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certaines fonctions contenues dans utils permettent d'obtenir les chemins vers les r√©pertoires cl√©s du projet\n",
    "# Ici, on r√©cup√®re le chemin vers le dossier {{package_name}}-data\n",
    "data_path = utils.get_data_path()\n",
    "# On charge les textes pour regarder leur contenu\n",
    "df = pd.read_csv(os.path.join(data_path, 'texts.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 Analyse rapide <a class=\"anchor\" id=\"analyse\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nombre de lignes / colonnes\n",
    "n_rows = df.shape[0]\n",
    "n_columns = df.shape[1]\n",
    "print(f\"Nombre de lignes : {n_rows}\")\n",
    "print(f\"Nombre de colonnes : {n_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de 10 lignes al√©atoires\n",
    "df.sample(10).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs manquantes\n",
    "for col in df.columns:\n",
    "    nb_missing = df[col].isna().sum()\n",
    "    print(f\"Valeurs manquantes pour la colonne \\033[1m{col}\\033[0m : {nb_missing} -> {round(nb_missing / n_rows * 100, 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la cible\n",
    "ax = sns.countplot(x=df['author'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4 D√©coupage du jeu de donn√©es en train / test <a class=\"anchor\" id=\"decoupage\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tout d'abord **d√©couper notre dataset en deux parties**, un ensemble d'entrainement et un ensemble de test afin de pouvoir entra√Æner et tester notre mod√®le (nous ne fabriquons pas d'ensemble de validation pour simplifier la pr√©sentation). \n",
    "\n",
    "Pour cela, nous allons utiliser les scripts contenus dans le package. Les scripts sont des aides pour effectuer les op√©rations courantes de Data Science. Rien ne vous emp√™che de cr√©er vos propres scripts !  \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Pour couper en deux le dataset, proc√©dez de la mani√®re suivante :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le r√©pertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le r√©pertoire `{{package_name}}-scripts/utils`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts/utils\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le script de d√©coupe du dataset pour r√©aliser une s√©paration \"stratified\" : \n",
    "\n",
    "    ```bash\n",
    "    python 0_split_train_valid_test.py -f texts.csv --perc_train 0.6 --perc_valid 0.0 --perc_test 0.4\n",
    "    ```\n",
    "    \n",
    "    Note : les scripts vont automatiquement chercher √† charger les fichiers de donn√©es, mod√®les, etc. directement depuis les r√©pertoires du projet pr√©vus √† cet effet (e.g. `{{package_name}}-data`, `{{package_name}}-models`, ...)\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Vous pouvez alors voir que deux fichiers, `texts_train.csv` et `texts_test.csv` ont √©t√© cr√©√©s dans `{{package_name}}-data`. \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "On peut regarder √† quoi ressemble ce nouveau jeu de donn√©es :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme nous allons le voir, certains jeux de donn√©es peuvent √™tre accompagn√©s d'une premi√®re ligne de metadata.\n",
    "# On conseille donc d'utiliser la fonction utils.read_csv qui va simplement v√©rifier la pr√©sence de cette ligne\n",
    "df_train, metadata_train = utils.read_csv(os.path.join(data_path, 'texts_train.csv'))\n",
    "df_test, metadata_test = utils.read_csv(os.path.join(data_path, 'texts_test.csv'))\n",
    "\n",
    "print('---------------------')\n",
    "print('------- TRAIN -------')\n",
    "print('---------------------')\n",
    "print(f\"M√©tadonn√©es train : {metadata_train}\")\n",
    "print('Echantillon :')\n",
    "display(df_train.sample(5).head(5))\n",
    "print('---------------------')\n",
    "print('------- TEST -------')\n",
    "print('---------------------')\n",
    "print(f\"M√©tadonn√©es test : {metadata_test}\")\n",
    "print('Echantillon :')\n",
    "display(df_test.sample(5).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si par hasard, vous avez fait une fausse manipulation et que vous devez reg√©n√©rer les fichiers de train / test, vous pouvez tout simplement ajouter l'option `--overwrite` pour √©craser les fichiers erron√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.5 Preprocessing sur les textes <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "Nous allons maintenant faire une √©tape de pr√©processing sur les textes afin de les normaliser et de simplifier l'entrainement de nos mod√®les. Pour cela, nous allons utiliser le script `1_preprocess_data.py` situ√© dans `{{package_name}}-scripts`.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Pour pr√©processer nos donn√©es textuelles :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le r√©pertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le r√©pertoire `{{package_name}}-scripts`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le script de pr√©processing : \n",
    "\n",
    "    ```bash\n",
    "    python 1_preprocess_data.py -f texts_train.csv --input_col text\n",
    "    ```\n",
    "    Notes :\n",
    "    - `--input_col` permet de pr√©ciser sur quelle colonne appliquer le preprocessing.\n",
    "    - On applique le preprocessing uniquement sur le jeu d'entrainement (et le jeu de validation si on en avait un)\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Un nouveau fichier est donc cr√©√© dans le r√©pertoire `{{package_name}}-data` : `texts_train_preprocess_P1.csv`.  \n",
    "Ce fichier est identique au fichier de base, sauf qu'il poss√®de une colonne suppl√©mentaire ('preprocessed_text') qui contient le texte modifi√©, et une ligne de metadata qui pr√©cise quel preprocessing a √©t√© appliqu√© (e.g. `#preprocess_P1`).\n",
    "\n",
    "Cette m√©tadonn√©e sera r√©utilis√©e par nos mod√®les pour savoir quel preprocessing doit √™tre appliqu√©e sur une nouvelle entr√©e en amont de la pr√©diction.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "On peut regarder √† quoi ressemble ce nouveau jeu de donn√©es :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed, metadata_train_preprocessed = utils.read_csv(os.path.join(data_path, 'texts_train_preprocess_P1.csv'))\n",
    "print('------------------------------------')\n",
    "print('------- TRAIN - PREPROCESSED -------')\n",
    "print('------------------------------------')\n",
    "print(f\"M√©tadonn√©es train - preprocessed : {metadata_train_preprocessed}\")\n",
    "print('Echantillon :')\n",
    "display(df_train_preprocessed.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le pr√©processing appliqu√© est celui fourni de base par le package mais il est tr√®s facile d'ajouter ses propres pipelines de preprocessing.\n",
    "\n",
    "Pour cela :\n",
    "\n",
    "- Ouvrez le fichier : `{{package_name}}/preprocessing/preprocess.py`.  \n",
    "\n",
    "\n",
    "- Dans ce module, vous voyez que l'ensemble des pipelines de preprocessing sont renseign√©es dans la fonction `get_preprocessors_dict`. C'est ici que vous pouvez rajouter vos pipelines personnalis√©es.  \n",
    "\n",
    "\n",
    "- On peut √©galement jeter un coup d'oeil √† la fonction `preprocess_sentence_P1` qui indique les diff√©rentes √©tapes de pr√©processing (pour plus d'informations, il suffit de lire la documentation du package words_n_fun, une librairie facilitant tout le travail de manipulation de texte).\n",
    "\n",
    "- Si vous avez l'oeil, vous pouvez remarquer que certains accents n'ont pas √©t√© trait√©s correctement par la pipeline `preprocess_sentence_P1`. On va donc corriger cela. Pour ce faire, il suffit de rajouter `'remove_accents'` en premi√®re √©tape dans la pipeline de la fonction `preprocess_sentence_P1`. Puis relancez :\n",
    "\n",
    "    ```bash\n",
    "    python 1_preprocess_data.py -f texts_train.csv --input_col text\n",
    "    ```\n",
    "    Note : Par d√©faut, ce script √©crase les anciennes versions (comportement susceptible de changer dans le futur).\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Les accents sont maintenant correctement trait√©s comme vous pouvez le v√©rifiez en utilisant la cellule ci-dessous.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed, metadata_train_preprocessed = utils.read_csv(os.path.join(data_path, 'texts_train_preprocess_P1.csv'))\n",
    "print('------------------------------------')\n",
    "print('------- TRAIN - PREPROCESSED -------')\n",
    "print('------------------------------------')\n",
    "print(f\"M√©tadonn√©es train - preprocessed : {metadata_train_preprocessed}\")\n",
    "print('Echantillon :')\n",
    "display(df_train_preprocessed.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que, de mani√®re g√©n√©rale, il est **fortement conseill√© de cr√©er une nouvelle pipeline de pr√©processing plut√¥t que d'en modifier une existante**.  \n",
    "En effet, si un de vos anciens mod√®les utilisait cette pipeline, ses performances vont changer car il utilisera maintenant la nouvelle (qui a le m√™me nom!).  \n",
    "Comme nous sommes ici au d√©but d'un projet et que nous n'avons pas encore entra√Æn√© de mod√®les, nous pouvons modifier la pipeline de pr√©processing.\n",
    "\n",
    "N.B. : Ce comportement sera certainement am√©lior√© dans les prochaines mises √† jour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.6. Entrainement d'un premier mod√®le <a class=\"anchor\" id=\"model1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entra√Æner un premier mod√®le en utilisant le script `2_training.py`\n",
    "\n",
    "Pour cela :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le r√©pertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le r√©pertoire `{{package_name}}-scripts`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le script d'entrainement : \n",
    "\n",
    "    ```bash\n",
    "    python 2_training.py -f texts_train_preprocess_P1.csv --x_col preprocessed_text --y_col author\n",
    "    ```\n",
    "    Note :\n",
    "    - Par d√©faut, le mod√®le entrain√© sera un simple TF-IDF + SVM sur les donn√©es (attention, √ßa overfit !)\n",
    "    - Plusieurs autres mod√®les sont propos√©s, il suffit d'aller commenter / d√©commenter les lignes correspondantes dans le fichier d'entrainement `2_training.py`.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Si vous allez dans `{{package_name}}-models/model_tfidf_svm` vous allez voir un dossier du type `model_tfidf_svm_{YYYY_MM_DD-hh_mm_ss}`. Il s'agit du dossier de sauvegarde du mod√®le que nous venons d'entrainer, cr√©√© automatiquement par le script d'entra√Ænement.  \n",
    "\n",
    "Vous pouvez par exemple voir le f1_score sur l'ensemble d'entrainement, la matrice de confusion sur l'ensemble d'entra√Ænement etc. Notez que nous aurions pu sp√©cifier un dataset de validation, on aurait ainsi eu acc√®s √† des m√©triques sur ce dataset. \n",
    "\n",
    "Ce dossier contient notamment des fichiers .pkl qui vont nous permettre de recharger notre mod√®le, soit directement par notre package (en mode 'model agnostic'), soit par la librairie du mod√®le (en mode 'standalone', e.g. Sklearn, TensorFlow, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.7. Pr√©dictions avec notre premier mod√®le <a class=\"anchor\" id=\"predictions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons entrain√© un premier mod√®le, nous voulons le r√©utiliser pour faire des pr√©dictions sur notre jeu de test !\n",
    "Nous pourrions utiliser le script `3_predict.py` qui permet de faire des pr√©dictions sur un jeu de test, mais nous allons le faire directement dans ce notebook dans le cadre de la formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du mod√®le entrain√©\n",
    "# TODO : changer {YYYY_MM_DD-hh_mm_ss} pour correspondre au nom de votre mod√®le ! (cf {{package_name}}-models/model_tfidf_svm)\n",
    "model, model_conf = utils_models.load_model('model_tfidf_svm_{YYYY_MM_DD-hh_mm_ss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voil√†, le mod√®le est charg√©, pr√™t √† √™tre utilis√©. Ce que nous allons directement faire sur l'ensemble de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par charg√© le jeu de donn√©e de test\n",
    "df_test, _ = utils.read_csv(os.path.join(data_path, 'texts_test.csv'))\n",
    "\n",
    "# On r√©cup√®re le preprocessing √† partir des configurations du mod√®le ...\n",
    "preprocess_str = model_conf['preprocess_str']\n",
    "preprocessor = preprocess.get_preprocessor(preprocess_str)\n",
    "# ... et on l'applique √† notre jeu de test\n",
    "df_test['preprocessed_text'] = preprocessor(df['text'])\n",
    "\n",
    "# On calcul nos pr√©dictions\n",
    "y_pred = model.predict(df_test['preprocessed_text'], return_proba=False)\n",
    "\n",
    "# On utilise la fonction inverse_transform pour r√©cup√©rer un format 'lisible' des pr√©dictions\n",
    "# Note: ici, dans un cas mono-label, la fonction ne fait rien de particulier\n",
    "df_test['predictions_1'] = list(model.inverse_transform(np.array(y_pred)))\n",
    "\n",
    "# Affichage\n",
    "display(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a nos pr√©dictions (qui n'ont pas l'air super ...), on peut √©valuer les performances sur notre jeu de test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy sur le jeu de test : {round((df_test['author'] == df_test['predictions_1']).sum() / df.shape[0] * 100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais, il est tout nul ce mod√®le !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.8. Cr√©ation d'un second mod√®le \"maison\" <a class=\"anchor\" id=\"maison\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rem√©dier √† nos mauvais r√©sultats, on pourrait essayer d'autres mod√®les propos√©s par notre package dans le script d'entrainement, mais √† la place nous allons utiliser une autre mani√®re de faire afin d'illustrer la puissance des frameworks.  \n",
    "Nous allons **cr√©er notre propre classe de mod√®le**, qui incorporera tous les fonctionnalit√©s du package que nous avons d√©j√† vu (sauvegarde automatique du mod√®le, chargement du mod√®le, calcul des m√©triques, etc.). \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "La logique que nous allons appliquer est simple. Au lieu d'appliquer un TF-IDF + SVM √† des livres entiers, nous allons d√©couper les livres en 'phrases' et faire apprendre le mod√®le sur ces 'phrases'.  \n",
    "Pour pr√©dire l'auteur d'un livre, nous allons donc d√©couper en 'phrases', pr√©dire pour chaque 'phrase' un auteur et prendre pour pr√©diction finale l'auteur qui a le plus de 'phrases' lui correspondant.  \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.  D√©coupage en phrases <a class=\"anchor\" id=\"phrases\"></a>\n",
    "\n",
    "On doit donc d'abord cr√©er une fonction qui prend un texte et qui le d√©coupe en phrase.  \n",
    "Comme V0, on va tout simplement enlever quelques ponctuations et d√©couper le texte tous les `nb_word_sentence` mots.  \n",
    "Un exemple est donn√© dans le fichier `utils_tutorial_fr.py` (situ√© au m√™me endroit que ce notebook), mais vous pouvez d√©finir votre propre fonction si vous le souhaitez :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_tutorial_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentences(text: str, nb_word_sentence: int = 10) -> List[str]:\n",
    "    '''Transforms a text in sentences.\n",
    "\n",
    "    Args:\n",
    "        text (str) : The text to cut in sentences\n",
    "    Kwargs:\n",
    "        nb_word_sentence (int) : The number of words in a sentence\n",
    "    Returns:\n",
    "        list : A list of sentences\n",
    "    '''\n",
    "    return utils_tutorial_fr.text_to_sentences(text, nb_word_sentence)  # A MODIFIER SI VOUS SOUHAITEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons son fonctionnement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Quelques musiciens accordaient leurs hautbois et leurs deÃÅchirants violons, des groupes se formaient\n",
    " autour de la tente, et des yeux de paysans se fixaient avec eÃÅtonnement et volupteÃÅ sur la grande enseigne ouÃÄ eÃÅtaient\n",
    " eÃÅcrits en lettres rouges et noires ces mots gigantesques : troupe acrobatique du sieur Pedrillo.\n",
    " Plus loin sur un carreÃÅ de toile peinte l‚Äôon distinguait facilement un homme aux formes athleÃÅtiques nu comme un sauvage\n",
    " et levant sur son dos une quantiteÃÅ eÃÅnorme de poids. Une banderole tricolore lui sortait de la bouche sur laquelle\n",
    " eÃÅtait eÃÅcrit : Je suis l‚ÄôHercule du Nord. Vous dire ce que le pierrot hurla sur son estrade, vous le savez aussi\n",
    " bien que moi, certes dans votre enfance vous vous eÃÇtes plus d‚Äôune fois arreÃÇteÃÅ devant cette sceÃÄne grotesque\n",
    " et vous avez ri comme les autres des coups de poing et des coups de pied qui viennent aÃÄ chaque instant\n",
    " interrompre l‚ÄôOrateur au milieu de son discours ou de sa narration. Dans la tente c‚ÄôeÃÅtait un spectacle\n",
    " diffeÃÅrent : trois enfants dont le plus jeune avait aÃÄ peine sept ans, sautaient sur la balustrade inteÃÅrieure\n",
    " de l‚Äôescalier, ou bien s‚ÄôexercÃßaient sur la corde aÃÄ la RepreÃÅsentation.'''\n",
    "text_to_sentences(text, nb_word_sentence=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.2.  Cr√©ation d'une nouvelle classe de mod√®le <a class=\"anchor\" id=\"new_class\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons cr√©er la classe `ModelAuthor` qui va impl√©menter notre id√©e de mod√®le.  \n",
    "Pour rappel, on veut toujours faire un mod√®le TF-IDF + SVM, mais on veut l'appliquer √† des phrases et non pas √† des textes entiers.\n",
    "Notre classe va donc descendre de la classe `ModelTfidfSvm`, et on va surcharger certaines fonctions :\n",
    "- `fit` : avant d'entrainer notre mod√®le, on veut split le texte en phrases\n",
    "- `predict` : avant de faire une pr√©diction, on veut aussi split notre texte en phrases\n",
    "- `predict_proba` : pareil que predict (√† noter qu'ici on a un cas particulier car le SVM ne retourne pas de pr√©diction)\n",
    "- `save` : on va rajouter un param√®tre √† notre mod√®le, il faut penser le sauvegarder\n",
    "- `reload_from_standalone` : pareil, quand on veut recharger un mod√®le 'standalone', il faut rajouter ce nouveau param√®tre\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "A vous de compl√©ter la classe suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO : La fonction utils_tutorial_fr.df_texts_to_df_sentences permet de split les textes en phrases\n",
    "#        et de retourner une dataframe avec toutes les phrases et les auteurs associ√©s.\n",
    "\n",
    "\n",
    "class ModelAuthor(?????):\n",
    "\n",
    "    _default_name = 'model_author'  # Utilis√© pour le dossier de sauvegarde\n",
    "\n",
    "    \n",
    "    def __init__(self, ?????, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.????? = ?????  # Param√®tre √† rajouter : nombre de mots par phrase\n",
    "        # Dans ce tutoriel, on ne g√®re pas les cas multilabel\n",
    "        if self.multi_label:\n",
    "            raise ValueError(\"On ne g√®re pas les cas multilabel\")\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train, **kwargs) -> None:\n",
    "        '''Entrainement du mod√®le'''\n",
    "        df_train_sentences = ?????  # Split des textes en phrases avec couples phrases / auteurs\n",
    "        new_x_train = df_train_sentences['sentence']\n",
    "        new_y_train = df_train_sentences['author']\n",
    "        super().fit(new_x_train, new_y_train)\n",
    "\n",
    "        \n",
    "    def predict(self, x_test, return_proba: bool = False, **kwargs) -> np.ndarray:\n",
    "        '''Prediction du mod√®le'''\n",
    "        # On process texte par texte\n",
    "        list_predictions = []\n",
    "        for text in x_test:\n",
    "            # On r√©cup√®re la pr√©diction sur chaque phrase du texte\n",
    "            sentences = text_to_sentences(text, nb_word_sentence=?????)\n",
    "            predictions = super().predict(sentences)\n",
    "            # On compte le nombre d'occurrences\n",
    "            counter_author_predictions = dict(Counter(list(predictions)))\n",
    "\n",
    "            # Si on ne retourne pas de probabilit√©s, on incr√©mente juste la liste de pr√©dictions\n",
    "            if not return_proba:\n",
    "                predicted_author = max(counter_author_predictions, key=counter_author_predictions.get)\n",
    "                ??????  # On ajoute l'auteur predit √† la liste\n",
    "            else:\n",
    "                # On va consid√©rer les probabilit√©s comme le pourcentage de phrases attribu√©es √† chaque auteur\n",
    "                nb_sentences = len(sentences)\n",
    "                list_probas = [counter_author_predictions.get(author, 0) / nb_sentences for author in self.list_classes]\n",
    "                list_predictions.append(list_probas)\n",
    "        \n",
    "        # Return\n",
    "        return np.array(list_predictions)\n",
    "\n",
    "    \n",
    "    def predict_proba(self, x_test, **kwargs) -> np.ndarray:\n",
    "        return self.predict(x_test, return_proba=?????, **kwargs)\n",
    "    \n",
    "    \n",
    "    def save(self, json_data=None) -> None:\n",
    "        '''Sauvegarde du mod√®le'''\n",
    "        if json_data is None:\n",
    "            json_data = {}\n",
    "        json_data['?????'] = self.?????\n",
    "        # Save\n",
    "        super().save(json_data=json_data)\n",
    "        \n",
    "    \n",
    "    def reload_from_standalone(self, **kwargs) -> None:\n",
    "        '''Recharge un mod√®le √† partir de sa sauvegarde standalone et de son fichier de conf'''\n",
    "        super().reload_from_standalone(**kwargs)\n",
    "        configuration_path = kwargs.get('configuration_path', None)\n",
    "        with open(configuration_path, 'r', encoding='{{default_encoding}}') as f:\n",
    "            configs = json.load(f)\n",
    "        self.????? = configs.get('trained', self.?????)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons cette nouvelle classe !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "df_train_preprocessed, metadata_train_preprocessed = utils.read_csv(os.path.join(data_path, 'texts_train_preprocess_P1.csv'))\n",
    "model = ModelAuthor(nb_word_sentence=100)\n",
    "x_train, y_train = df_train_preprocessed['preprocessed_text'], df_train_preprocessed['author']\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Sauvegarde\n",
    "preprocess_str = metadata_train_preprocessed.replace('#', '')\n",
    "model.save({'preprocess_str': preprocess_str})\n",
    "\n",
    "# Pr√©dictions sur tests\n",
    "df_test, _ = utils.read_csv(os.path.join(data_path, 'texts_test.csv'))\n",
    "preprocessor = preprocess.get_preprocessor(preprocess_str)\n",
    "x_test = preprocessor(df_test['text'])\n",
    "predictions = model.predict(x_test)\n",
    "probas = model.predict_proba(x_test)\n",
    "df_results = pd.DataFrame({\n",
    "    'text': df_test['text'],\n",
    "    'true_author': df_test['author'],\n",
    "    'predicted_author': predictions,\n",
    "    'proba': probas.max(axis=1)\n",
    "})\n",
    "display(df_results)\n",
    "\n",
    "# Evaluations\n",
    "y_pred_train = model.predict(x_train, return_proba=False)\n",
    "model.get_and_save_metrics(y_train, y_pred_train, type_data='train')\n",
    "model.get_and_save_metrics(df_test['author'], predictions, type_data='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'on est bien meilleur qu'avant sur notre jeu de test ! Super !\n",
    "\n",
    "Si vous voulez, vous pouvez v√©rifier dans votre r√©pertoire de mod√®les que le nouveau mod√®le apparait bien (dans un sous dossier `model_author`).\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Ainsi en moins d'une centaine de ligne de code, nous avons **d√©velopp√© une nouvelle classe de mod√®le** qui va pouvoir utiliser tous les outils du projet.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.3.  Packaging de notre nouvelle classe mod√®le <a class=\"anchor\" id=\"packaging\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a notre nouvelle classe de mod√®le, on a envie de **l'int√©grer √† notre package**.  \n",
    "Cela va nous permettre d'utiliser tous les scripts mis √† disposition, d'ajouter des tests unitaires pour v√©rifier le bon fonctionnement de notre classe, et de simplifier l'industrialisation de nos futurs mod√®les.\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Pour ce faire, il va falloir encapsuler notre classe dans un fichier python.  \n",
    "Pour acc√©l√©rer la pr√©sentation, nous l'avons d√©j√† effectu√© pour vous dans le fichier `model_author.py` situ√© dans le m√™me dossier que ce notebook. Libre √† vous de l'√©diter si vous voulez ajouter vos sp√©cificit√©s (notamment sur le split en phrases).\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Pour incorporer notre nouvelle classe, il faut :\n",
    "\n",
    "- Copier le fichier `model_author.py` √† l'endroit o√π se trouve tous les autres classes de mod√®les : `{{package_name}}/models_training/`\n",
    "\n",
    "\n",
    "- Modifier les imports du script `2_training.py` pour rajouter notre classe de mod√®le :\n",
    "\n",
    "    ```python\n",
    "    from {{package_name}}.models_training.model_author import ModelAuthor\n",
    "    ```\n",
    "\n",
    "- Ajouter un exemple d'instanciation dans le script `2_training.py` (cf. tous les exemples comment√©s au milieu du script) :\n",
    "\n",
    "    ```python\n",
    "    model = ModelAuthor(x_col=x_col, y_col=y_col, \n",
    "                        level_save=level_save,\n",
    "                        multi_label=multi_label,\n",
    "                        nb_word_sentence=100)\n",
    "    ```\n",
    "\n",
    "- (NE PAS FAIRE POUR LE TUTO) : Ajouter l'import dans 0_reload_model.py et mettre √† jour le dictionnaire `model_type_dicts`\n",
    "\n",
    "\n",
    "- (NE PAS FAIRE POUR LE TUTO) : D√©velopper les TUs associ√©s √† notre classe (√† grand coups de copier-collers !)\n",
    "\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.4.  R√©utilisation de notre classe avec les scripts du projet <a class=\"anchor\" id=\"scripting\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va r√©entrainer notre nouveau mod√®le directement avec les scripts du projet.  \n",
    "\n",
    "\n",
    "Pour ce faire, il vous suffit de commenter le mod√®le TF-IDF + SVM et de d√©commenter le mod√®le 'Author' dans `2_training.py` (le bout de code que vous venez de rajouter), et de relancer les m√™mes commandes que pr√©cedemment :\n",
    "\n",
    "- Entrainement : `python 2_training.py -f texts_train_preprocess_P1.csv --x_col preprocessed_text --y_col author`  \n",
    "\n",
    "\n",
    "- Pr√©dictions : `python 3_predict.py -f texts_test.csv --x_col text --y_col author -m model_author_{YYYY_MM_DD-hh_mm_ss}`  \n",
    "\n",
    "    Note : il faut changer le nom du mod√®le par le v√¥tre.\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Maintenant vous pouvez vous amusez √† changer les param√®tres de notre nouveau mod√®le (nombre de mots par phrases, param√®tres tfidf (cf. classe `ModelTfidfSvm`), etc.) pour essayer d'obtenir le meilleur score possible sur le jeu de test !\n",
    "\n",
    "Attention de ne pas overfitter dessus ! üòÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "## 4. It's showtime ! <a class=\"anchor\" id=\"showtime\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons finalement utiliser un autre outil incorpor√© dans les frameworks : le d√©monstrateur.  \n",
    "\n",
    "Il est souvent n√©cessaire de montrer le fonctionnement d'un mod√®le IA √† votre m√©tier, mais aussi √† vos pairs.  \n",
    "Nous avons donc inclus un d√©monstrateur Streamlit √† nos projets pour vous permettre de d√©montrer tr√®s rapidement les performances de vos meilleurs mod√®les !\n",
    "\n",
    "Pour le lancer, il vous suffit de :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le r√©pertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le r√©pertoire `{{package_name}}-scripts`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le d√©monstrateur streamlit : \n",
    "\n",
    "    ```bash\n",
    "    streamlit run 4_demonstrator.py\n",
    "    ```\n",
    "    Note : par d√©faut streamlit se lance sur le port 8501 de votre localhost : http://localhost:8501\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Dans le menu de gauche, vous pouvez s√©lectionner le mod√®le que vous voulez utiliser, soit le premier mod√®le TF-IDF + SVM que nous avons entrain√©, soit un de nos nouveaux mod√®les bas√© sur le d√©coupage en phrases.  \n",
    "Il suffit ensuite d'entrer le texte que vous voulez tester et appuyer sur predict pour acc√©der √† la pr√©diction du mod√®le (bon id√©alement il faudrait copier un livre entier üôÑ vous pouvez cocher 'Multiple lines').\n",
    "\n",
    "\n",
    "Note : vous pouvez √©videmment adapter ce d√©monstrateur √† vos besoin en √©ditant le fichier `4_demonstrator.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "## 5. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "\n",
    "Ce petit exemple illustre la mani√®re d'utiliser les frameworks :\n",
    "\n",
    "- On part d'un projet contenant tous les outils pour d√©velopper rapidement un mod√®le.  \n",
    "\n",
    "\n",
    "- On teste quelques mod√®les inclus pour voir si un correspond √† notre cas d'usage.  \n",
    "\n",
    "\n",
    "- Si besoin, on d√©veloppe son propre mod√®le en h√©ritant des classes d√©finies dans le projet pour profiter de toutes les fonctions incluses dedans.\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "\n",
    "Pour la partie industrialisation, nous vous invitons √† consulter notre Github.  \n",
    "\n",
    "L'id√©e globale est : \n",
    "- Uploader les mod√®les sur un syst√®me de stockages d'artefacts  \n",
    "\n",
    "\n",
    "- Build votre package et l'uploader (e.g. sur PyPI)  \n",
    "\n",
    "\n",
    "- Cr√©er un autre projet API qui import votre package  \n",
    "\n",
    "\n",
    "- T√©l√©charger votre mod√®le √† l'initialisation du service API et exposer une fonction `predict`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
