{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: This tutorial is in **FRENCH** only.*\n",
    "\n",
    "# Tutoriel Jules Vernes\n",
    "\n",
    "\n",
    "<img src=\"images/jules_verne_1.png\" style='float: left; width: 30%; margin:10%; margin-top:0%; margin-bottom:0%'><img src=\"images/jules_verne_2.png\" style='float: left; width: 30%; margin:10%; margin-top:0%; margin-bottom:0%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Pré-requis :**\n",
    "\n",
    "- Ce notebook doit avoir été généré avec le template NLP du projet Gabarit.\n",
    "\n",
    "\n",
    "- Télécharger le fichier `texts.csv` se trouvant ici (https://github.com/OSS-Pole-Emploi/gabarit/tree/main/gabarit/template_nlp/nlp_data) et le placer dans le répertoire `{{package_name}}-data` du package que vous avez généré.\n",
    "\n",
    "\n",
    "- **Lancer ce notebook avec un kernel utilisant l'environnement virtuel de votre projet**. Pour ce faire, il suffit de faire : `python -m ipykernel install --user --name=your_venv_name` (une fois votre environnement virtuel activé). Evidemment, le projet généré doit être installé sur cet environnement virtuel. Il peut être nécessaire de rafraîchir votre navigateur pour voir le kernel apparaître.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières :\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "* [1. Objectifs](#objectifs)\n",
    "\n",
    "\n",
    "* [2. Principes](#principes)\n",
    "\n",
    "\n",
    "* [3. Entrainement d'un modèle de détection d'auteurs 'out of the box'](#entrainement)\n",
    "\n",
    "\n",
    ">  * [3.1 Imports et fonctions utilitaires](#imports)\n",
    "\n",
    ">  * [3.2 Chargement des données](#data)\n",
    "\n",
    ">  * [3.3 Analyse rapide](#analyse)\n",
    "\n",
    ">  * [3.4 Découpage du jeu de données en train / test](#decoupage)\n",
    "\n",
    ">  * [3.5 Preprocessing sur les textes](#preprocessing)\n",
    "\n",
    ">  * [3.6. Entrainement d'un premier modèle](#model1)\n",
    "\n",
    ">  * [3.7. Prédictions avec notre premier modèle](#predictions)\n",
    "\n",
    ">  * [3.8. Création d'un second modèle \"maison\"](#maison)\n",
    ">>  * [3.8.1.  Découpage en phrases](#phrases)\n",
    ">>  * [3.8.2.  Création d'une nouvelle classe de modèle](#new_class)\n",
    ">>  * [3.8.3.  Packaging de notre nouvelle classe modèle](#packaging)\n",
    ">>  * [3.8.4.  Réutilisation de notre classe avec les scripts du projet](#scripting)\n",
    "\n",
    "* [4. It's showtime ](#showtime)\n",
    "\n",
    "\n",
    "* [5. Conclusion](#conclusion)\n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectifs <a class=\"anchor\" id=\"objectifs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- L'objectif principal de ce tutoriel est de vous introduire au projet Open Source `Gabarit`, développé par l’équipe IA de Pôle Emploi.\n",
    "\n",
    "\n",
    "- Nous allons traiter un cas d'usage \"jouet\" : la détection automatique de l'auteur d'un texte du XIXème siècle.\n",
    "\n",
    "\n",
    "- A la fin de ce tutoriel, nous espérons vous donner tous les outils nécessaires pour démarrer rapidement un nouveau projet d'IA, propre et prêt à être industrialisé.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Principes <a class=\"anchor\" id=\"principes\"></a>\n",
    "\n",
    "\n",
    "- Ce projet a été developpé dans une logique d'accélération des développements de nos projets IA, et dans l'objectif de fournir une base de code commune facilitant le passage en industrialisation de nos modèles.\n",
    "\n",
    "\n",
    "- Pour ce faire, nous proposons différents **templates** de projets IA :  \n",
    "<br>  \n",
    "<br>  \n",
    "    - Template NLP : classification de données textuelles  \n",
    "<br>  \n",
    "<br>  \n",
    "    \n",
    "    - Template NUM : classification et régression sur des données numériques  \n",
    "<br>  \n",
    "<br>  \n",
    "    \n",
    "    - Template VISION : classification d'images et détection d'objets  \n",
    "<br>  \n",
    "<br>  \n",
    "    \n",
    "    \n",
    "- L'idée n'est pas de créer un outil clé en main 'low-code', mais bien de fournir une base de code que chaque Data Scientist pourra adapter à son projet. Il aura ainsi le contrôle de tout ce qu'il s'y passe.\n",
    "\n",
    "\n",
    "- Les templates sont très similaires entre eux, même s'ils ont évidemment chacun leur spécificité.  \n",
    "\n",
    "\n",
    "- Les projets générés sont composés d'une partie 'package' et d'une partie 'scripts' qui permettent notamment de lancer les entrainements.  \n",
    "\n",
    "\n",
    "- Le projet est construit de manière à ce que tous les modèles soient '**agnostic**'. De cette manière, on appelera un modèle toujours de la même façon (e.g. model.predict(...)) peu importe qu'il s'agisse d'un modèle Sklearn ou TensorFlow.\n",
    "\n",
    "\n",
    "- Des démonstrateurs Streamlit sont intégrés aux projets pour pouvoir rapidement faire des présentations à votre métier !\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrainement d'un modèle de détection d'auteurs 'out of the box' <a class=\"anchor\" id=\"entrainement\"></a>\n",
    "\n",
    "On va partir de textes de différents auteurs du XIXème siècle et fabriquer un modèle permettant **d'identifier automatiquement son auteur**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 Imports et fonctions utilitaires <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "from {{package_name}} import utils\n",
    "from {{package_name}}.preprocessing import preprocess\n",
    "from {{package_name}}.models_training import utils_models\n",
    "from {{package_name}}.models_training.models_sklearn.model_tfidf_svm import ModelTfidfSvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 Chargement des données <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certaines fonctions contenues dans utils permettent d'obtenir les chemins vers les répertoires clés du projet\n",
    "# Ici, on récupère le chemin vers le dossier {{package_name}}-data\n",
    "data_path = utils.get_data_path()\n",
    "# On charge les textes pour regarder leur contenu\n",
    "df = pd.read_csv(os.path.join(data_path, 'texts.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 Analyse rapide <a class=\"anchor\" id=\"analyse\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nombre de lignes / colonnes\n",
    "n_rows = df.shape[0]\n",
    "n_columns = df.shape[1]\n",
    "print(f\"Nombre de lignes : {n_rows}\")\n",
    "print(f\"Nombre de colonnes : {n_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de 10 lignes aléatoires\n",
    "df.sample(10).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs manquantes\n",
    "for col in df.columns:\n",
    "    nb_missing = df[col].isna().sum()\n",
    "    print(f\"Valeurs manquantes pour la colonne \\033[1m{col}\\033[0m : {nb_missing} -> {round(nb_missing / n_rows * 100, 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la cible\n",
    "ax = sns.countplot(x=df['author'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4 Découpage du jeu de données en train / test <a class=\"anchor\" id=\"decoupage\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tout d'abord **découper notre dataset en deux parties**, un ensemble d'entrainement et un ensemble de test afin de pouvoir entraîner et tester notre modèle (nous ne fabriquons pas d'ensemble de validation pour simplifier la présentation). \n",
    "\n",
    "Pour cela, nous allons utiliser les scripts contenus dans le package. Les scripts sont des aides pour effectuer les opérations courantes de Data Science. Rien ne vous empêche de créer vos propres scripts !  \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Pour couper en deux le dataset, procédez de la manière suivante :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le répertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le répertoire `{{package_name}}-scripts/utils`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts/utils\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le script de découpe du dataset pour réaliser une séparation \"stratified\" : \n",
    "\n",
    "    ```bash\n",
    "    python 0_split_train_valid_test.py -f texts.csv --perc_train 0.6 --perc_valid 0.0 --perc_test 0.4\n",
    "    ```\n",
    "    \n",
    "    Note : les scripts vont automatiquement chercher à charger les fichiers de données, modèles, etc. directement depuis les répertoires du projet prévus à cet effet (e.g. `{{package_name}}-data`, `{{package_name}}-models`, ...)\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Vous pouvez alors voir que deux fichiers, `texts_train.csv` et `texts_test.csv` ont été créés dans `{{package_name}}-data`. \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "On peut regarder à quoi ressemble ce nouveau jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme nous allons le voir, certains jeux de données peuvent être accompagnés d'une première ligne de metadata.\n",
    "# On conseille donc d'utiliser la fonction utils.read_csv qui va simplement vérifier la présence de cette ligne\n",
    "df_train, metadata_train = utils.read_csv(os.path.join(data_path, 'texts_train.csv'))\n",
    "df_test, metadata_test = utils.read_csv(os.path.join(data_path, 'texts_test.csv'))\n",
    "\n",
    "print('---------------------')\n",
    "print('------- TRAIN -------')\n",
    "print('---------------------')\n",
    "print(f\"Métadonnées train : {metadata_train}\")\n",
    "print('Echantillon :')\n",
    "display(df_train.sample(5).head(5))\n",
    "print('---------------------')\n",
    "print('------- TEST -------')\n",
    "print('---------------------')\n",
    "print(f\"Métadonnées test : {metadata_test}\")\n",
    "print('Echantillon :')\n",
    "display(df_test.sample(5).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si par hasard, vous avez fait une fausse manipulation et que vous devez regénérer les fichiers de train / test, vous pouvez tout simplement ajouter l'option `--overwrite` pour écraser les fichiers erronés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.5 Preprocessing sur les textes <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "Nous allons maintenant faire une étape de préprocessing sur les textes afin de les normaliser et de simplifier l'entrainement de nos modèles. Pour cela, nous allons utiliser le script `1_preprocess_data.py` situé dans `{{package_name}}-scripts`.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Pour préprocesser nos données textuelles :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le répertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le répertoire `{{package_name}}-scripts`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le script de préprocessing : \n",
    "\n",
    "    ```bash\n",
    "    python 1_preprocess_data.py -f texts_train.csv --input_col text\n",
    "    ```\n",
    "    Notes :\n",
    "    - `--input_col` permet de préciser sur quelle colonne appliquer le preprocessing.\n",
    "    - On applique le preprocessing uniquement sur le jeu d'entrainement (et le jeu de validation si on en avait un)\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Un nouveau fichier est donc créé dans le répertoire `{{package_name}}-data` : `texts_train_preprocess_P1.csv`.  \n",
    "Ce fichier est identique au fichier de base, sauf qu'il possède une colonne supplémentaire ('preprocessed_text') qui contient le texte modifié, et une ligne de metadata qui précise quel preprocessing a été appliqué (e.g. `#preprocess_P1`).\n",
    "\n",
    "Cette métadonnée sera réutilisée par nos modèles pour savoir quel preprocessing doit être appliquée sur une nouvelle entrée en amont de la prédiction.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "On peut regarder à quoi ressemble ce nouveau jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed, metadata_train_preprocessed = utils.read_csv(os.path.join(data_path, 'texts_train_preprocess_P1.csv'))\n",
    "print('------------------------------------')\n",
    "print('------- TRAIN - PREPROCESSED -------')\n",
    "print('------------------------------------')\n",
    "print(f\"Métadonnées train - preprocessed : {metadata_train_preprocessed}\")\n",
    "print('Echantillon :')\n",
    "display(df_train_preprocessed.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le préprocessing appliqué est celui fourni de base par le package mais il est très facile d'ajouter ses propres pipelines de preprocessing.\n",
    "\n",
    "Pour cela :\n",
    "\n",
    "- Ouvrez le fichier : `{{package_name}}/preprocessing/preprocess.py`.  \n",
    "\n",
    "\n",
    "- Dans ce module, vous voyez que l'ensemble des pipelines de preprocessing sont renseignées dans la fonction `get_preprocessors_dict`. C'est ici que vous pouvez rajouter vos pipelines personnalisées.  \n",
    "\n",
    "\n",
    "- On peut également jeter un coup d'oeil à la fonction `preprocess_sentence_P1` qui indique les différentes étapes de préprocessing (pour plus d'informations, il suffit de lire la documentation du package words_n_fun, une librairie facilitant tout le travail de manipulation de texte).\n",
    "\n",
    "- Si vous avez l'oeil, vous pouvez remarquer que certains accents n'ont pas été traités correctement par la pipeline `preprocess_sentence_P1`. On va donc corriger cela. Pour ce faire, il suffit de rajouter `'remove_accents'` en première étape dans la pipeline de la fonction `preprocess_sentence_P1`. Puis relancez :\n",
    "\n",
    "    ```bash\n",
    "    python 1_preprocess_data.py -f texts_train.csv --input_col text --overwrite\n",
    "    ```\n",
    "    Note : Il faut rajouter `--overwrite` pour écraser le fichier précédent\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Les accents sont maintenant correctement traités comme vous pouvez le vérifiez en utilisant la cellule ci-dessous.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed, metadata_train_preprocessed = utils.read_csv(os.path.join(data_path, 'texts_train_preprocess_P1.csv'))\n",
    "print('------------------------------------')\n",
    "print('------- TRAIN - PREPROCESSED -------')\n",
    "print('------------------------------------')\n",
    "print(f\"Métadonnées train - preprocessed : {metadata_train_preprocessed}\")\n",
    "print('Echantillon :')\n",
    "display(df_train_preprocessed.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que, de manière générale, il est **fortement conseillé de créer une nouvelle pipeline de préprocessing plutôt que d'en modifier une existante**.  \n",
    "En effet, si un de vos anciens modèles utilisait cette pipeline, ses performances vont changer car il utilisera maintenant la nouvelle (qui a le même nom!).  \n",
    "Comme nous sommes ici au début d'un projet et que nous n'avons pas encore entraîné de modèles, nous pouvons modifier la pipeline de préprocessing.\n",
    "\n",
    "N.B. : Ce comportement sera certainement amélioré dans les prochaines mises à jour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.6. Entrainement d'un premier modèle <a class=\"anchor\" id=\"model1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entraîner un premier modèle en utilisant le script `2_training.py`\n",
    "\n",
    "Pour cela :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le répertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le répertoire `{{package_name}}-scripts`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le script d'entrainement : \n",
    "\n",
    "    ```bash\n",
    "    python 2_training.py -f texts_train_preprocess_P1.csv --x_col preprocessed_text --y_col author\n",
    "    ```\n",
    "    Note :\n",
    "    - Par défaut, le modèle entrainé sera un simple TF-IDF + SVM sur les données (attention, ça overfit !)\n",
    "    - Plusieurs autres modèles sont proposés, il suffit d'aller commenter / décommenter les lignes correspondantes dans le fichier d'entrainement `2_training.py`.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Si vous allez dans `{{package_name}}-models/model_tfidf_svm` vous allez voir un dossier du type `model_tfidf_svm_{YYYY_MM_DD-hh_mm_ss}`. Il s'agit du dossier de sauvegarde du modèle que nous venons d'entrainer, créé automatiquement par le script d'entraînement.  \n",
    "\n",
    "Vous pouvez par exemple voir le f1_score sur l'ensemble d'entrainement, la matrice de confusion sur l'ensemble d'entraînement etc. Notez que nous aurions pu spécifier un dataset de validation, on aurait ainsi eu accès à des métriques sur ce dataset. \n",
    "\n",
    "Ce dossier contient notamment des fichiers .pkl qui vont nous permettre de recharger notre modèle, soit directement par notre package (en mode 'model agnostic'), soit par la librairie du modèle (en mode 'standalone', e.g. Sklearn, TensorFlow, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.7. Prédictions avec notre premier modèle <a class=\"anchor\" id=\"predictions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons entrainé un premier modèle, nous voulons le réutiliser pour faire des prédictions sur notre jeu de test !\n",
    "Nous pourrions utiliser le script `3_predict.py` qui permet de faire des prédictions sur un jeu de test, mais nous allons le faire directement dans ce notebook dans le cadre de la formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle entrainé\n",
    "# TODO : changer {YYYY_MM_DD-hh_mm_ss} pour correspondre au nom de votre modèle ! (cf {{package_name}}-models/model_tfidf_svm)\n",
    "model, model_conf = utils_models.load_model('model_tfidf_svm_{YYYY_MM_DD-hh_mm_ss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà, le modèle est chargé, prêt à être utilisé. Ce que nous allons directement faire sur l'ensemble de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par chargé le jeu de donnée de test\n",
    "df_test, _ = utils.read_csv(os.path.join(data_path, 'texts_test.csv'))\n",
    "\n",
    "# On récupère le preprocessing à partir des configurations du modèle ...\n",
    "preprocess_str = model_conf['preprocess_str']\n",
    "preprocessor = preprocess.get_preprocessor(preprocess_str)\n",
    "# ... et on l'applique à notre jeu de test\n",
    "df_test['preprocessed_text'] = preprocessor(df['text'])\n",
    "\n",
    "# On calcul nos prédictions\n",
    "y_pred = model.predict(df_test['preprocessed_text'], return_proba=False)\n",
    "\n",
    "# On utilise la fonction inverse_transform pour récupérer un format 'lisible' des prédictions\n",
    "# Note: ici, dans un cas mono-label, la fonction ne fait rien de particulier\n",
    "df_test['predictions_1'] = list(model.inverse_transform(np.array(y_pred)))\n",
    "\n",
    "# Affichage\n",
    "display(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a nos prédictions (qui n'ont pas l'air super ...), on peut évaluer les performances sur notre jeu de test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy sur le jeu de test : {round((df_test['author'] == df_test['predictions_1']).sum() / df_test.shape[0] * 100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais, il est tout nul ce modèle !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.8. Création d'un second modèle \"maison\" <a class=\"anchor\" id=\"maison\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour remédier à nos mauvais résultats, on pourrait essayer d'autres modèles proposés par notre package dans le script d'entrainement, mais à la place nous allons utiliser une autre manière de faire afin d'illustrer la puissance des frameworks.  \n",
    "Nous allons **créer notre propre classe de modèle**, qui incorporera tous les fonctionnalités du package que nous avons déjà vu (sauvegarde automatique du modèle, chargement du modèle, calcul des métriques, etc.). \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "La logique que nous allons appliquer est simple. Au lieu d'appliquer un TF-IDF + SVM à des livres entiers, nous allons découper les livres en 'phrases' et faire apprendre le modèle sur ces 'phrases'.  \n",
    "Pour prédire l'auteur d'un livre, nous allons donc découper en 'phrases', prédire pour chaque 'phrase' un auteur et prendre pour prédiction finale l'auteur qui a le plus de 'phrases' lui correspondant.  \n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.  Découpage en phrases <a class=\"anchor\" id=\"phrases\"></a>\n",
    "\n",
    "On doit donc d'abord créer une fonction qui prend un texte et qui le découpe en phrase.  \n",
    "Comme V0, on va tout simplement enlever quelques ponctuations et découper le texte tous les `nb_word_sentence` mots.  \n",
    "Un exemple est donné dans le fichier `utils_tutorial_fr.py` (situé au même endroit que ce notebook), mais vous pouvez définir votre propre fonction si vous le souhaitez :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_tutorial_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentences(text: str, nb_word_sentence: int = 10) -> List[str]:\n",
    "    '''Transforms a text in sentences.\n",
    "\n",
    "    Args:\n",
    "        text (str) : The text to cut in sentences\n",
    "    Kwargs:\n",
    "        nb_word_sentence (int) : The number of words in a sentence\n",
    "    Returns:\n",
    "        list : A list of sentences\n",
    "    '''\n",
    "    return utils_tutorial_fr.text_to_sentences(text, nb_word_sentence)  # A MODIFIER SI VOUS SOUHAITEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons son fonctionnement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Quelques musiciens accordaient leurs hautbois et leurs déchirants violons, des groupes se formaient\n",
    " autour de la tente, et des yeux de paysans se fixaient avec étonnement et volupté sur la grande enseigne où étaient\n",
    " écrits en lettres rouges et noires ces mots gigantesques : troupe acrobatique du sieur Pedrillo.\n",
    " Plus loin sur un carré de toile peinte l’on distinguait facilement un homme aux formes athlétiques nu comme un sauvage\n",
    " et levant sur son dos une quantité énorme de poids. Une banderole tricolore lui sortait de la bouche sur laquelle\n",
    " était écrit : Je suis l’Hercule du Nord. Vous dire ce que le pierrot hurla sur son estrade, vous le savez aussi\n",
    " bien que moi, certes dans votre enfance vous vous êtes plus d’une fois arrêté devant cette scène grotesque\n",
    " et vous avez ri comme les autres des coups de poing et des coups de pied qui viennent à chaque instant\n",
    " interrompre l’Orateur au milieu de son discours ou de sa narration. Dans la tente c’était un spectacle\n",
    " différent : trois enfants dont le plus jeune avait à peine sept ans, sautaient sur la balustrade intérieure\n",
    " de l’escalier, ou bien s’exerçaient sur la corde à la Représentation.'''\n",
    "text_to_sentences(text, nb_word_sentence=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.2.  Création d'une nouvelle classe de modèle <a class=\"anchor\" id=\"new_class\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer la classe `ModelAuthor` qui va implémenter notre idée de modèle.  \n",
    "Pour rappel, on veut toujours faire un modèle TF-IDF + SVM, mais on veut l'appliquer à des phrases et non pas à des textes entiers.\n",
    "Notre classe va donc descendre de la classe `ModelTfidfSvm`, et on va surcharger certaines fonctions :\n",
    "- `fit` : avant d'entrainer notre modèle, on veut split le texte en phrases\n",
    "- `predict` : avant de faire une prédiction, on veut aussi split notre texte en phrases\n",
    "- `predict_proba` : pareil que predict (à noter qu'ici on a un cas particulier car le SVM ne retourne pas de prédiction)\n",
    "- `save` : on va rajouter un paramètre à notre modèle, il faut penser à le sauvegarder\n",
    "- `_init_new_instance_from_configs` : pareil, quand on veut recharger un modèle 'standalone', il faut rajouter ce nouveau paramètre\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "A vous de compléter la classe suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO : La fonction utils_tutorial_fr.df_texts_to_df_sentences permet de split les textes en phrases\n",
    "#        et de retourner une dataframe avec toutes les phrases et les auteurs associés.\n",
    "\n",
    "\n",
    "class ModelAuthor(?????):\n",
    "\n",
    "    _default_name = 'model_author'  # Utilisé pour le dossier de sauvegarde\n",
    "\n",
    "    \n",
    "    def __init__(self, ?????, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.????? = ?????  # Paramètre à rajouter : nombre de mots par phrase\n",
    "        # Dans ce tutoriel, on ne gère pas les cas multilabel\n",
    "        if self.multi_label:\n",
    "            raise ValueError(\"On ne gère pas les cas multilabel\")\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train, **kwargs) -> None:\n",
    "        '''Entrainement du modèle'''\n",
    "        df_train_sentences = ?????  # Split des textes en phrases avec couples phrases / auteurs\n",
    "        new_x_train = df_train_sentences['sentence']\n",
    "        new_y_train = df_train_sentences['author']\n",
    "        super().fit(new_x_train, new_y_train)\n",
    "\n",
    "        \n",
    "    def predict(self, x_test, return_proba: bool = False, **kwargs) -> np.ndarray:\n",
    "        '''Prediction du modèle'''\n",
    "        # On process texte par texte\n",
    "        list_predictions = []\n",
    "        for text in x_test:\n",
    "            # On récupère la prédiction sur chaque phrase du texte\n",
    "            sentences = text_to_sentences(text, nb_word_sentence=?????)\n",
    "            predictions = super().predict(sentences)\n",
    "            # On compte le nombre d'occurrences\n",
    "            counter_author_predictions = dict(Counter(list(predictions)))\n",
    "\n",
    "            # Si on ne retourne pas de probabilités, on incrémente juste la liste de prédictions\n",
    "            if not return_proba:\n",
    "                predicted_author = max(counter_author_predictions, key=counter_author_predictions.get)\n",
    "                ??????  # On ajoute l'auteur predit à la liste\n",
    "            else:\n",
    "                # On va considérer les probabilités comme le pourcentage de phrases attribuées à chaque auteur\n",
    "                nb_sentences = len(sentences)\n",
    "                list_probas = [counter_author_predictions.get(author, 0) / nb_sentences for author in self.list_classes]\n",
    "                list_predictions.append(list_probas)\n",
    "        \n",
    "        # Return\n",
    "        return np.array(list_predictions)\n",
    "\n",
    "    \n",
    "    def predict_proba(self, x_test, **kwargs) -> np.ndarray:\n",
    "        return self.predict(x_test, return_proba=?????, **kwargs)\n",
    "    \n",
    "    \n",
    "    def save(self, json_data=None) -> None:\n",
    "        '''Sauvegarde du modèle'''\n",
    "        if json_data is None:\n",
    "            json_data = {}\n",
    "        json_data['?????'] = self.?????\n",
    "        # Save\n",
    "        super().save(json_data=json_data)\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def _init_new_instance_from_configs(cls, configs):\n",
    "        '''Inits a new instance from a set of configurations\n",
    "\n",
    "        Args:\n",
    "            configs: a set of configurations of a model to be reloaded\n",
    "        Returns:\n",
    "            ModelClass: the newly generated class\n",
    "        '''\n",
    "        # Call parent\n",
    "        model = super()._init_new_instance_from_configs(configs)\n",
    "\n",
    "        # Try to read the following attributes from configs and, if absent, keep the current one\n",
    "        for attribute in ['?????']:\n",
    "            setattr(model, attribute, configs.get(attribute, getattr(model, attribute)))\n",
    "\n",
    "        # Return the new model\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons cette nouvelle classe !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "df_train_preprocessed, metadata_train_preprocessed = utils.read_csv(os.path.join(data_path, 'texts_train_preprocess_P1.csv'))\n",
    "model = ModelAuthor(nb_word_sentence=100)\n",
    "x_train, y_train = df_train_preprocessed['preprocessed_text'], df_train_preprocessed['author']\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Sauvegarde\n",
    "preprocess_str = metadata_train_preprocessed.replace('#', '')\n",
    "model.save({'preprocess_str': preprocess_str})\n",
    "\n",
    "# Prédictions sur tests\n",
    "df_test, _ = utils.read_csv(os.path.join(data_path, 'texts_test.csv'))\n",
    "preprocessor = preprocess.get_preprocessor(preprocess_str)\n",
    "x_test = preprocessor(df_test['text'])\n",
    "predictions = model.predict(x_test)\n",
    "probas = model.predict_proba(x_test)\n",
    "df_results = pd.DataFrame({\n",
    "    'text': df_test['text'],\n",
    "    'true_author': df_test['author'],\n",
    "    'predicted_author': predictions,\n",
    "    'proba': probas.max(axis=1)\n",
    "})\n",
    "display(df_results)\n",
    "\n",
    "# Evaluations\n",
    "y_pred_train = model.predict(x_train, return_proba=False)\n",
    "model.get_and_save_metrics(y_train, y_pred_train, type_data='train')\n",
    "model.get_and_save_metrics(df_test['author'], predictions, type_data='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'on est bien meilleur qu'avant sur notre jeu de test ! Super !\n",
    "\n",
    "Si vous voulez, vous pouvez vérifier dans votre répertoire de modèles que le nouveau modèle apparait bien (dans un sous dossier `model_author`).\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Ainsi en moins d'une centaine de ligne de code, nous avons **développé une nouvelle classe de modèle** qui va pouvoir utiliser tous les outils du projet.\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.3.  Packaging de notre nouvelle classe modèle <a class=\"anchor\" id=\"packaging\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a notre nouvelle classe de modèle, on a envie de **l'intégrer à notre package**.  \n",
    "Cela va nous permettre d'utiliser tous les scripts mis à disposition, d'ajouter des tests unitaires pour vérifier le bon fonctionnement de notre classe, et de simplifier l'industrialisation de nos futurs modèles.\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "Pour ce faire, il va falloir encapsuler notre classe dans un fichier python.  \n",
    "Pour accélérer la présentation, nous l'avons déjà effectué pour vous dans le fichier `model_author.py` situé dans le même dossier que ce notebook. Libre à vous de l'éditer si vous voulez ajouter vos spécificités (notamment sur le split en phrases).\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Pour incorporer notre nouvelle classe, il faut :\n",
    "\n",
    "- Copier le fichier `model_author.py` à l'endroit où se trouve tous les autres classes de modèles : `{{package_name}}/models_training/`\n",
    "\n",
    "\n",
    "- Modifier les imports du script `2_training.py` pour rajouter notre classe de modèle :\n",
    "\n",
    "    ```python\n",
    "    from {{package_name}}.models_training.model_author import ModelAuthor\n",
    "    ```\n",
    "\n",
    "- Ajouter un exemple d'instanciation dans le script `2_training.py` (cf. tous les exemples commentés au milieu du script) :\n",
    "\n",
    "    ```python\n",
    "    model = ModelAuthor(x_col=x_col, y_col=y_col, \n",
    "                        level_save=level_save,\n",
    "                        multi_label=multi_label,\n",
    "                        nb_word_sentence=100)\n",
    "    ```\n",
    "\n",
    "- (NE PAS FAIRE POUR LE TUTO) : Ajouter l'import dans 0_reload_model.py et mettre à jour le dictionnaire `model_type_dicts`\n",
    "\n",
    "\n",
    "- (NE PAS FAIRE POUR LE TUTO) : Développer les TUs associés à notre classe (à grand coups de copier-collers !)\n",
    "\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.4.  Réutilisation de notre classe avec les scripts du projet <a class=\"anchor\" id=\"scripting\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va réentrainer notre nouveau modèle directement avec les scripts du projet.  \n",
    "\n",
    "\n",
    "Pour ce faire, il vous suffit de commenter le modèle TF-IDF + SVM et de décommenter le modèle 'Author' dans `2_training.py` (le bout de code que vous venez de rajouter), et de relancer les mêmes commandes que précedemment :\n",
    "\n",
    "- Entrainement : `python 2_training.py -f texts_train_preprocess_P1.csv --x_col preprocessed_text --y_col author`  \n",
    "\n",
    "\n",
    "- Prédictions : `python 3_predict.py -f texts_test.csv --x_col text --y_col author -m model_author_{YYYY_MM_DD-hh_mm_ss}`  \n",
    "\n",
    "    Note : il faut changer le nom du modèle par le vôtre.\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Maintenant vous pouvez vous amusez à changer les paramètres de notre nouveau modèle (nombre de mots par phrases, paramètres tfidf (cf. classe `ModelTfidfSvm`), etc.) pour essayer d'obtenir le meilleur score possible sur le jeu de test !\n",
    "\n",
    "Attention de ne pas overfitter dessus ! 😅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "## 4. It's showtime ! <a class=\"anchor\" id=\"showtime\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons finalement utiliser un autre outil incorporé dans les frameworks : le démonstrateur.  \n",
    "\n",
    "Il est souvent nécessaire de montrer le fonctionnement d'un modèle IA à votre métier, mais aussi à vos pairs.  \n",
    "Nous avons donc inclus un démonstrateur Streamlit à nos projets pour vous permettre de démontrer très rapidement les performances de vos meilleurs modèles !\n",
    "\n",
    "Pour le lancer, il vous suffit de :\n",
    "\n",
    "\n",
    "- Lancez un terminal et naviguez dans le répertoire de votre projet  \n",
    "\n",
    "\n",
    "- Activez votre environnement virtuel  \n",
    "\n",
    "    (e.g. sur unix : `source venv_{{package_name}}/bin/activate`)\n",
    "\n",
    "\n",
    "- Naviguez dans le répertoire `{{package_name}}-scripts`\n",
    "\n",
    "    ```bash\n",
    "    cd {{package_name}}-scripts\n",
    "    ```\n",
    "\n",
    "\n",
    "- Appelez le démonstrateur streamlit : \n",
    "\n",
    "    ```bash\n",
    "    streamlit run 4_demonstrator.py\n",
    "    ```\n",
    "    Note : par défaut streamlit se lance sur le port 8501 de votre localhost : http://localhost:8501\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "Dans le menu de gauche, vous pouvez sélectionner le modèle que vous voulez utiliser, soit le premier modèle TF-IDF + SVM que nous avons entrainé, soit un de nos nouveaux modèles basé sur le découpage en phrases.  \n",
    "Il suffit ensuite d'entrer le texte que vous voulez tester et appuyer sur predict pour accéder à la prédiction du modèle (bon idéalement il faudrait copier un livre entier 🙄 vous pouvez cocher 'Multiple lines').\n",
    "\n",
    "\n",
    "Note : vous pouvez évidemment adapter ce démonstrateur à vos besoin en éditant le fichier `4_demonstrator.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "## 5. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "\n",
    "Ce petit exemple illustre la manière d'utiliser les frameworks :\n",
    "\n",
    "- On part d'un projet contenant tous les outils pour développer rapidement un modèle.  \n",
    "\n",
    "\n",
    "- On teste quelques modèles inclus pour voir si un correspond à notre cas d'usage.  \n",
    "\n",
    "\n",
    "- Si besoin, on développe son propre modèle en héritant des classes définies dans le projet pour profiter de toutes les fonctions incluses dedans.\n",
    "\n",
    "\n",
    "<br>  \n",
    "<br>  \n",
    "\n",
    "\n",
    "\n",
    "Pour la partie industrialisation, nous vous invitons à consulter notre Github.  \n",
    "\n",
    "L'idée globale est : \n",
    "- Uploader les modèles sur un système de stockages d'artefacts  \n",
    "\n",
    "\n",
    "- Build votre package et l'uploader (e.g. sur PyPI)  \n",
    "\n",
    "\n",
    "- Créer un autre projet API qui import votre package  \n",
    "\n",
    "\n",
    "- Télécharger votre modèle à l'initialisation du service API et exposer une fonction `predict`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
