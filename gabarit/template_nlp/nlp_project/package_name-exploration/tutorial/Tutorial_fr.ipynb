{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from {{package_name}} import utils\n",
    "from {{package_name}}.models_training import utils_models\n",
    "from {{package_name}}.models_training.model_tfidf_svm import ModelTfidfSvm \n",
    "\n",
    "from utils_tutorial_fr import (text_to_sentence, predict_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les textes\n",
    "data_path = utils.get_data_path()\n",
    "df_texts = pd.read_csv(os.path.join(data_path, 'texts.csv'), sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentence_size = 50\n",
    "min_sentence_word = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On constitue les phrases\n",
    "list_phrases = []\n",
    "for index, row in df_texts.iterrows():\n",
    "    text = row['text']\n",
    "    author = row['author']\n",
    "    book = row['book']\n",
    "    # Cette fonction transforme un texte en phrases\n",
    "    sentences = text_to_sentence(text, min_sentence_size, min_sentence_word)\n",
    "    list_phrases = list_phrases+[(sentence, author, book) for sentence in sentences]\n",
    "df_phrases = pd.DataFrame(list_phrases, columns=['sentence', 'author', 'book'])\n",
    "set_author = set(df_texts['author'])\n",
    "\n",
    "# On regarde la répartition des phrases par auteur\n",
    "df_phrases.value_counts('author')/len(df_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On mélange le dataset\n",
    "df_to_split = df_phrases.sample(frac=1)\n",
    "\n",
    "# On sélectionne un livre par auteur qui sera dans l'ensemble de validation\n",
    "dict_books_to_valid = {}\n",
    "for author in set_author:\n",
    "    set_books = set(df_texts[df_texts['author']==author]['book'])\n",
    "    dict_books_to_valid[author] = random.sample(set_books, k=1)[0]\n",
    "df_valid = df_to_split[df_to_split['book'].isin(dict_books_to_valid.values())].copy()\n",
    "\n",
    "# On sélectionne un autre livre par auteur qui sera dans l'ensemble de test\n",
    "dict_books_to_test = {}\n",
    "for author in set_author:\n",
    "    set_books = set(df_texts[df_texts['author']==author]['book'])\n",
    "    set_books.remove(dict_books_to_valid[author])\n",
    "    dict_books_to_test[author] = random.sample(set_books, k=1)[0]\n",
    "df_test = df_to_split[df_to_split['book'].isin(dict_books_to_test.values())].copy()\n",
    "\n",
    "# Tout le reste est dans l'ensemble d'entrainement\n",
    "df_train = df_to_split.copy()\n",
    "df_train = df_train[~df_train['book'].isin(dict_books_to_valid.values())]\n",
    "df_train = df_train[~df_train['book'].isin(dict_books_to_test.values())]\n",
    "\n",
    "# On sauvegarde les datasets\n",
    "utils.to_csv(df_train, os.path.join(data_path, 'dataset_texts_train.csv'))\n",
    "utils.to_csv(df_valid, os.path.join(data_path, 'dataset_texts_valid.csv'))\n",
    "utils.to_csv(df_test, os.path.join(data_path, 'dataset_texts_test.csv'))\n",
    "\n",
    "# On regarde la répartition des phrases par auteur dans l'ensemble d'entrainement\n",
    "df_train.value_counts('author')/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait un léger tuning\n",
    "dict_result = {}\n",
    "count =0\n",
    "for ngram_range in [(1, 1), (1, 2)]:\n",
    "    for C in [0.1, 0.5, 1, 2]:\n",
    "        model = ModelTfidfSvm(tfidf_params = {'ngram_range': ngram_range}, svc_params={'C':C})\n",
    "        model.fit(df_train['sentence'], df_train['author'], x_valid=df_valid['sentence'], y_valid=df_valid['author'])\n",
    "        df_train['pred'] = model.predict(df_train['sentence'])\n",
    "        df_valid['pred'] = model.predict(df_valid['sentence'])\n",
    "        score_train = f1_score(df_train['author'], df_train['pred'], average='macro')\n",
    "        score_val = f1_score(df_valid['author'], df_valid['pred'], average='macro')\n",
    "        dict_tmp = {'score_train':round(score_train, 5), 'score_val':round(score_val, 5), 'ngram_range':ngram_range, 'C':C}\n",
    "        dict_result[count] = dict_tmp.copy()\n",
    "        count += 1\n",
    "        print(dict_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sélectionne le meilleur modèle\n",
    "model = ModelTfidfSvm(tfidf_params = {'ngram_range': (1, 2)}, svc_params={'C':1})\n",
    "model.fit(df_train['sentence'], df_train['author'], x_valid=df_valid['sentence'], y_valid=df_valid['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prédit sur le test\n",
    "df_test['pred'] = model.predict(df_test['sentence'])\n",
    "score = f1_score(df_test['author'], df_test['pred'], average='macro')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(predict_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = {}\n",
    "# Pour chaque auteur\n",
    "for author, book in dict_books_to_test.items():\n",
    "    # Récupère le texte\n",
    "    row = df_texts[df_texts['book']==book]\n",
    "    text = row.iloc[0]['text']\n",
    "    length = len(text)\n",
    "    # Prédit l'auteur\n",
    "    prediction, counter, nb_sentences = predict_author(text, model, min_sentence_size, min_sentence_word, perc_sample=1.0)\n",
    "    # Enregistre le résultat\n",
    "    dict_result[author] = {'prediction': prediction, 'counter': counter, 'length': len(text), 'nb_sentences':nb_sentences}\n",
    "# Vérifie si le résultat est bon pour tous les auteurs\n",
    "print({key==value['prediction'] for key, value in dict_result.items()})\n",
    "# Montre les résultats\n",
    "dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv_template_nlp",
   "language": "python",
   "name": "venv_template_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
