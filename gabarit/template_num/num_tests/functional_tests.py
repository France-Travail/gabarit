#!/usr/bin/env python3
# Starts all functional tests
# Copyright (C) <2018-2022>  <Agence Data Services, DSI PÃ´le Emploi>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

# Libs unittest
import unittest
from unittest.mock import Mock
from unittest.mock import patch

# utils libs
import os
import sys
import json
import shutil
import tempfile
import subprocess
import numpy as np
import pandas as pd
import importlib.util
from pathlib import Path
from datetime import datetime

from test_template_num import utils
from test_template_num.models_training import utils_models, model_aggregation
from test_template_num.models_training.classifiers import (model_rf_classifier, model_dense_classifier,
                                                           model_ridge_classifier, model_logistic_regression_classifier,
                                                           model_sgd_classifier, model_svm_classifier, model_knn_classifier,
                                                           model_gbt_classifier, model_lgbm_classifier, model_xgboost_classifier)
from test_template_num.models_training.regressors import (model_rf_regressor, model_dense_regressor,
                                                          model_elasticnet_regressor, model_bayesian_ridge_regressor,
                                                          model_kernel_ridge_regressor, model_svr_regressor,
                                                          model_sgd_regressor, model_knn_regressor, model_pls_regressor,
                                                          model_gbt_regressor, model_xgboost_regressor, model_lgbm_regressor)

def remove_dir(path):
    if os.path.isdir(path): shutil.rmtree(path)


class Case1_e2e_pipeline(unittest.TestCase):
    '''Class to test the project end to end'''

    def test01_CreateSamples(self):
        '''Test of the file utils/0_create_samples.py'''
        print("Test of the file utils/0_create_samples.py")

        # "Basic" case
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_create_samples.py -f mono_class_mono_label.csv -n 15"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_15_samples.csv')))
        df = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_15_samples.csv", sep=';', encoding='utf-8')
        self.assertEqual(df.shape[0], 15)

        # Double files
        double_files_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_create_samples.py -f mono_class_mono_label.csv multi_class_mono_label.csv -n 2000"
        self.assertEqual(subprocess.run(double_files_run, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_2000_samples.csv')))
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'multi_class_mono_label_2000_samples.csv')))
        df1 = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_2000_samples.csv", sep=';', encoding='utf-8')
        df2 = pd.read_csv(f"{full_path_lib}/test_template_num-data/multi_class_mono_label_2000_samples.csv", sep=';', encoding='utf-8')
        self.assertEqual(df1.shape[0], 210)
        self.assertEqual(df2.shape[0], 210)  # 210 row max

    def test02_MergeFiles(self):
        '''Test of the file utils/0_merge_files.py'''
        print("Test of the file utils/0_merge_files.py")

        # "Basic" case
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_merge_files.py -f mono_class_mono_label.csv multi_class_mono_label.csv -c col_1 col_2 y_col -o merged_file.csv"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'merged_file.csv')))
        df = pd.read_csv(f"{full_path_lib}/test_template_num-data/merged_file.csv", sep=';', encoding='utf-8')
        self.assertGreater(df.shape[0], 210)  # We check that there are more than 210 elements (ie. the size of one of the two files)

    def test03_SplitTrainValidTest(self):
        '''Test of the file utils/0_split_train_valid_test.py'''
        print("Test of the file utils/0_split_train_valid_test.py")

        # "Basic" case
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_class_mono_label.csv --split_type random --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col --seed 42"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_train.csv')))
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_valid.csv')))
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_test.csv')))
        df_train = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_train.csv", sep=';', encoding='utf-8')
        df_valid = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_valid.csv", sep=';', encoding='utf-8')
        df_test = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_test.csv", sep=';', encoding='utf-8')
        self.assertEqual(df_train.shape[0], 126)
        self.assertEqual(df_valid.shape[0], 42)
        self.assertEqual(df_test.shape[0], 42)

        # Test of perc_x arguments
        test_perc = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_class_mono_label.csv --split_type random --perc_train 0.3 --perc_valid 0.6 --perc_test 0.1 --y_col y_col --seed 42"
        self.assertEqual(subprocess.run(test_perc, shell=True).returncode, 0)
        df_train = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_train.csv", sep=';', encoding='utf-8')
        df_valid = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_valid.csv", sep=';', encoding='utf-8')
        df_test = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_test.csv", sep=';', encoding='utf-8')
        self.assertEqual(df_train.shape[0], 63)
        self.assertEqual(df_valid.shape[0], 126)
        self.assertEqual(df_test.shape[0], 21)

        # Test split_type stratified
        test_stratified = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_class_mono_label.csv --split_type stratified --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col --seed 42"
        self.assertEqual(subprocess.run(test_stratified, shell=True).returncode, 0)
        df_train = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_train.csv", sep=';', encoding='utf-8')
        df_valid = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_valid.csv", sep=';', encoding='utf-8')
        df_test = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_class_mono_label_test.csv", sep=';', encoding='utf-8')
        # Check number of elements
        self.assertEqual(df_train.shape[0], 126)
        self.assertEqual(df_valid.shape[0], 42)
        self.assertEqual(df_test.shape[0], 42)
        # Check stratified (we have 3/7 "1"s -> 0.428...)
        perc_oui_train = sum(df_train['y_col'] == "oui")/df_train.shape[0]
        self.assertGreater(perc_oui_train, 0.40)
        self.assertLess(perc_oui_train, 0.45)
        perc_oui_valid = sum(df_valid['y_col'] == "oui")/df_valid.shape[0]
        self.assertGreater(perc_oui_valid, 0.40)
        self.assertLess(perc_oui_valid, 0.45)
        perc_oui_test = sum(df_test['y_col'] == "oui")/df_test.shape[0]
        self.assertGreater(perc_oui_test, 0.40)
        self.assertLess(perc_oui_test, 0.45)

        # "Basic" case - regression (for compatibility)
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_output_regression.csv --split_type random --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col --seed 42"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_train.csv')))
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_valid.csv')))
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_test.csv')))
        df_train = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_output_regression_train.csv", sep=';', encoding='utf-8')
        df_valid = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_output_regression_valid.csv", sep=';', encoding='utf-8')
        df_test = pd.read_csv(f"{full_path_lib}/test_template_num-data/mono_output_regression_test.csv", sep=';', encoding='utf-8')
        self.assertEqual(df_train.shape[0], 126)
        self.assertEqual(df_valid.shape[0], 42)
        self.assertEqual(df_test.shape[0], 42)

    def test04_GenerateReport(self):
        '''Test of the file utils/0_generate_report.py'''
        print("Test of the file utils/0_generate_report.py")

        # We first create a sweetviz configuration file
        config_path = os.path.join(full_path_lib, "test_config.json")
        if os.path.exists(config_path):
            os.remove(config_path)
        with open(config_path, 'w') as f:
            json.dump({"open_browser": False}, f)

        # "Basic" case
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_generate_report.py -s mono_class_mono_label.csv --source_names source --config {config_path}"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, "test_template_num-data", "reports", "report_source.html")))

        # Compare datasets
        test_compare = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_generate_report.py -s mono_class_mono_label_train.csv --source_names train -c mono_class_mono_label_valid.csv mono_class_mono_label_test.csv --compare_names valid test --config {config_path}"
        self.assertEqual(subprocess.run(test_compare, shell=True).returncode, 0)
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, "test_template_num-data", "reports", "report_train_valid.html")))
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, "test_template_num-data", "reports", "report_train_test.html")))

        # With target
        # Sweetviz does not with categorical target. Hence, we'll create a temporary dataframe with a binary target.
        data_path = os.path.join(full_path_lib, 'test_template_num-data')
        original_dataset_path = os.path.join(data_path, 'mono_class_mono_label.csv')
        with tempfile.NamedTemporaryFile(dir=data_path) as tmp_file:
            # Read dataset, add a tmp target as binary class & save it in the tmp file
            df = pd.read_csv(original_dataset_path, sep=';', encoding='utf-8')
            df['tmp_target'] = df['y_col'].apply(lambda x: 1. if x == 'oui' else 0.)
            df.to_csv(tmp_file.name, sep=';', encoding='utf-8', index=None)
            test_target = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_generate_report.py -s {tmp_file.name} --source_names source_with_target -t tmp_target --config {config_path}"
            self.assertEqual(subprocess.run(test_target, shell=True).returncode, 0)
            self.assertTrue(os.path.exists(os.path.join(full_path_lib, "test_template_num-data", "reports", "report_source_with_target.html")))

        # Clean up sweetviz config path (useful ?)
        os.remove(config_path)

    def test05_PreProcessData(self):
        '''Test of the file 1_preprocess_data.py'''
        print("Test of the file 1_preprocess_data.py")

        # "Basic" case - classification
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/1_preprocess_data.py -f mono_class_mono_label_train.csv -p preprocess_P1 --target_cols y_col"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check if exists
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_train_preprocess_P1.csv')))
        df_train = pd.read_csv(os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_train_preprocess_P1.csv'), sep=';', encoding='utf-8', skiprows=1)
        # Check col num__col_1, num__col_2 & y_col exists, num is the transformer name
        self.assertTrue('num__col_1' in df_train.columns)
        self.assertTrue('num__col_2' in df_train.columns)
        self.assertTrue('y_col' in df_train.columns)
        # Check col x_col_1 value
        self.assertTrue(df_train['num__col_1'].values[2], 0.4142585780542456)
        # Check col y_col values
        self.assertEqual(sorted(df_train.y_col.unique()), ["non", "oui"])
        # Check pipeline has been saved
        pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
        self.assertTrue(os.path.exists(pipelines_dirpath))
        self.assertTrue(len(os.listdir(pipelines_dirpath)) >= 1)
        pipeline_path = os.path.join(pipelines_dirpath, os.listdir(pipelines_dirpath)[0])
        self.assertTrue('pipeline.info' in os.listdir(pipeline_path))
        self.assertTrue('pipeline.pkl' in os.listdir(pipeline_path))

        # "Basic" case - regression
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/1_preprocess_data.py -f mono_output_regression_train.csv -p preprocess_P1 --target_cols y_col"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check if exists
        self.assertTrue(os.path.exists(os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_train_preprocess_P1.csv')))
        df_train = pd.read_csv(os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_train_preprocess_P1.csv'), sep=';', encoding='utf-8', skiprows=1)
        # Check col num__col_1, num__col_2 & y_col exists, num is the transformer name
        self.assertTrue('num__col_1' in df_train.columns)
        self.assertTrue('num__col_2' in df_train.columns)
        self.assertTrue('y_col' in df_train.columns)
        # Check col x_col_1 value
        self.assertTrue(df_train['num__col_1'].values[2], 0.4142585780542456)
        # Check pipeline has been saved
        pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
        self.assertTrue(os.path.exists(pipelines_dirpath))
        self.assertTrue(len(os.listdir(pipelines_dirpath)) >= 1)
        pipeline_path = os.path.join(pipelines_dirpath, os.listdir(pipelines_dirpath)[-1])
        self.assertTrue('pipeline.info' in os.listdir(pipeline_path))
        self.assertTrue('pipeline.pkl' in os.listdir(pipeline_path))

    def test06_ApplyPipeline(self):
        '''Test of the file 2_apply_existing_pipeline.py'''
        print("Test of the file 2_apply_existing_pipeline.py")

        pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
        pipeline_name_classification = os.listdir(pipelines_dirpath)[0]
        pipeline_name_regression = os.listdir(pipelines_dirpath)[-1]

        # "Basic" case - classification
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/2_apply_existing_pipeline.py -f mono_class_mono_label_valid.csv -p {pipeline_name_classification} --target_cols y_col"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check if exists
        train_path = os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_train_preprocess_P1.csv')
        valid_path = os.path.join(full_path_lib, 'test_template_num-data', 'mono_class_mono_label_train_preprocess_P1.csv')
        self.assertTrue(os.path.exists(valid_path))
        # Check first line equals
        with open(train_path, 'r', encoding='utf-8') as f:
            first_line_train = f.readline()
        with open(valid_path, 'r', encoding='utf-8') as f:
            first_line_valid = f.readline()
        self.assertEqual(first_line_train, first_line_valid)
        # Check same preprocess (we test unique values)
        df_train = pd.read_csv(train_path, sep=';', encoding='utf-8', skiprows=1)
        df_valid = pd.read_csv(valid_path, sep=';', encoding='utf-8', skiprows=1)
        self.assertEqual(sorted(df_train.num__col_1.unique()), sorted(df_valid.num__col_1.unique()))
        self.assertEqual(sorted(df_train.num__col_2.unique()), sorted(df_valid.num__col_2.unique()))
        self.assertEqual(sorted(df_train.y_col.unique()), sorted(df_valid.y_col.unique()))

        # "Basic" case - regression
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/2_apply_existing_pipeline.py -f mono_output_regression_valid.csv -p {pipeline_name_regression} --target_cols y_col"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check if exists
        train_path = os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_train_preprocess_P1.csv')
        valid_path = os.path.join(full_path_lib, 'test_template_num-data', 'mono_output_regression_train_preprocess_P1.csv')
        self.assertTrue(os.path.exists(valid_path))
        # Check first line equals
        with open(train_path, 'r', encoding='utf-8') as f:
            first_line_train = f.readline()
        with open(valid_path, 'r', encoding='utf-8') as f:
            first_line_valid = f.readline()
        self.assertEqual(first_line_train, first_line_valid)
        # Check same preprocess (we test unique values)
        df_train = pd.read_csv(train_path, sep=';', encoding='utf-8', skiprows=1)
        df_valid = pd.read_csv(valid_path, sep=';', encoding='utf-8', skiprows=1)
        self.assertEqual(sorted(df_train.num__col_1.unique()), sorted(df_valid.num__col_1.unique()))
        self.assertEqual(sorted(df_train.num__col_2.unique()), sorted(df_valid.num__col_2.unique()))
        self.assertEqual(sorted(df_train.y_col.unique()), sorted(df_valid.y_col.unique()))

    def test07_TrainingE2E(self):
        '''Test of files 3_training_classification.py & 3_training_regression.py'''
        print("Test of files 3_training_classification.py & 3_training_regression.py")

        ################
        # Classification
        ################

        # "Basic" case
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/3_training_classification.py -f mono_class_mono_label_train_preprocess_P1.csv -y y_col --filename_valid mono_class_mono_label_valid_preprocess_P1.csv --mlflow_experiment gabarit_ci/mlflow_test"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check model saved
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        self.assertTrue(os.path.exists(save_model_dir))
        listdir = os.listdir(os.path.join(save_model_dir))
        self.assertEqual(len(listdir), 1)

        # With excluded_cols
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/3_training_classification.py -f mono_class_mono_label_train_preprocess_P1.csv -y y_col --filename_valid mono_class_mono_label_valid_preprocess_P1.csv --excluded_cols col_2 --mlflow_experiment gabarit_ci/mlflow_test"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check model saved
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        self.assertTrue(os.path.exists(save_model_dir))
        listdir = os.listdir(os.path.join(save_model_dir))
        self.assertEqual(len(listdir), 2)

        # Multilabel - no preprocess - no valid
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/3_training_classification.py -f mono_class_multi_label.csv -y y_col_1 y_col_2 --mlflow_experiment gabarit_ci/mlflow_test"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check model saved
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        self.assertTrue(os.path.exists(save_model_dir))
        listdir = os.listdir(os.path.join(save_model_dir))
        self.assertEqual(len(listdir), 3)

        ############
        # Regression
        ############
        # We didn't work on the file

        # "Basic" case
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/3_training_regression.py -f mono_output_regression_train.csv -y y_col --filename_valid mono_output_regression_valid.csv --mlflow_experiment gabarit_ci/mlflow_test"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check model saved
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_elasticnet_regressor')  # ElasticNet Regressor by default
        self.assertTrue(os.path.exists(save_model_dir))
        listdir = os.listdir(os.path.join(save_model_dir))
        self.assertEqual(len(listdir), 1)

        # With excluded_cols
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/3_training_regression.py -f mono_output_regression_train.csv -y y_col --filename_valid mono_output_regression_valid.csv --excluded_cols col_2 --mlflow_experiment gabarit_ci/mlflow_test"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check model saved
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_elasticnet_regressor')  # ElasticNet Regressor by default
        self.assertTrue(os.path.exists(save_model_dir))
        listdir = os.listdir(os.path.join(save_model_dir))
        self.assertEqual(len(listdir), 2)

    def test08_PredictE2E(self):
        '''Test of the file 4_predict.py'''
        print("Test of the file 4_predict.py")

        ################
        # Classification
        ################

        # "Basic" case
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        listdir = sorted(os.listdir(os.path.join(save_model_dir)))
        model_name = listdir[0]  # First or second one trained (ordered by date)
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/4_predict.py -f mono_class_mono_label_test.csv -m {model_name}"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check predictions
        save_predictions_dir = os.path.join(full_path_lib, 'test_template_num-data', 'predictions', 'mono_class_mono_label_test')
        self.assertTrue(os.path.exists(save_predictions_dir))
        listdir = os.listdir(os.path.join(save_predictions_dir))
        self.assertTrue(os.path.exists(os.path.join(save_predictions_dir, listdir[0], 'predictions.csv')))

        # Run with "y_col"
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        listdir = sorted(os.listdir(os.path.join(save_model_dir)))
        model_name = listdir[1]  # First or second one trained (ordered by date)
        run_with_y_col = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/4_predict.py -f mono_class_mono_label_test.csv -y y_col -m {model_name}"
        self.assertEqual(subprocess.run(run_with_y_col, shell=True).returncode, 0)
        # Check predictions
        listdir = sorted(os.listdir(os.path.join(save_predictions_dir)))
        self.assertTrue(os.path.exists(os.path.join(save_predictions_dir, listdir[-1], 'predictions_with_y_true.csv')))  # last folder

        # Multilabel
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        listdir = sorted(os.listdir(os.path.join(save_model_dir)))
        multilabel_run = listdir[2]  # Third one trained (ordered by date)
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/4_predict.py -f mono_class_multi_label.csv -m {multilabel_run}"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check predictions
        save_predictions_dir = os.path.join(full_path_lib, 'test_template_num-data', 'predictions', 'mono_class_multi_label')
        self.assertTrue(os.path.exists(save_predictions_dir))
        listdir = os.listdir(os.path.join(save_predictions_dir))
        self.assertTrue(os.path.exists(os.path.join(save_predictions_dir, listdir[0], 'predictions.csv')))

        # Multilabel -with y_col
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_ridge_classifier')  # Ridge Classifier by default
        listdir = sorted(os.listdir(os.path.join(save_model_dir)))
        model_name = listdir[2]  # Third one trained (ordered by date)
        run_with_y_col = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/4_predict.py -f mono_class_multi_label.csv -y y_col_1 y_col_2 -m {model_name}"
        self.assertEqual(subprocess.run(run_with_y_col, shell=True).returncode, 0)
        # Check predictions
        listdir = sorted(os.listdir(os.path.join(save_predictions_dir)))
        self.assertTrue(os.path.exists(os.path.join(save_predictions_dir, listdir[-1], 'predictions_with_y_true.csv')))  # last folder

        ################
        # Regression
        ################

        # "Basic" case
        save_model_dir = os.path.join(full_path_lib, 'test_template_num-models', 'model_elasticnet_regressor')  # ElasticNet Regressor by default
        listdir = sorted(os.listdir(os.path.join(save_model_dir)))
        model_name = listdir[0]
        basic_run = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/4_predict.py -f mono_output_regression_test.csv -m {model_name}"
        self.assertEqual(subprocess.run(basic_run, shell=True).returncode, 0)
        # Check predictions
        save_predictions_dir = os.path.join(full_path_lib, 'test_template_num-data', 'predictions', 'mono_class_mono_label_test')
        self.assertTrue(os.path.exists(save_predictions_dir))
        listdir = os.listdir(os.path.join(save_predictions_dir))
        self.assertTrue(os.path.exists(os.path.join(save_predictions_dir, listdir[0], 'predictions.csv')))

        # Run with "y_col"
        run_with_y_col = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/4_predict.py -f mono_output_regression_test.csv -y y_col -m {model_name}"
        self.assertEqual(subprocess.run(run_with_y_col, shell=True).returncode, 0)
        # Check predictions
        listdir = sorted(os.listdir(os.path.join(save_predictions_dir)))
        self.assertTrue(os.path.exists(os.path.join(save_predictions_dir, listdir[-1], 'predictions_with_y_true.csv')))  # last folder


def test_model_mono_class_mono_label(test_class, test_model):
    '''Generic function to test a given model for mono-class/mono-label'''

    # Check if files exist
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, 'configurations.json')))
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, f'{test_model.model_name}.pkl')))
    # Try some functions
    df_input_preds = pd.DataFrame({
        'col_1': [-5, 3],
        'col_2': [2, 2],
    })
    df_input_preds_prep = utils_models.apply_pipeline(df_input_preds, test_model.preprocess_pipeline)
    # predict
    preds = test_model.predict(df_input_preds_prep)
    test_class.assertEqual(list(preds), ['non', 'oui'])
    # predict_proba
    index_non = test_model.list_classes.index('non')
    index_oui = test_model.list_classes.index('oui')
    probas = test_model.predict_proba(df_input_preds_prep)
    test_class.assertGreater(probas[0][index_non], 0.5)
    test_class.assertLess(probas[0][index_oui], 0.5)
    test_class.assertGreater(probas[1][index_oui], 0.5)
    test_class.assertLess(probas[1][index_non], 0.5)
    # predict w/ return_proba=True
    probas2 = test_model.predict(df_input_preds_prep, return_proba=True)
    test_class.assertGreater(probas2[0][index_non], 0.5)
    test_class.assertLess(probas2[0][index_oui], 0.5)
    test_class.assertGreater(probas2[1][index_oui], 0.5)
    test_class.assertLess(probas2[1][index_non], 0.5)
    # predict_with_proba
    pred_proba = test_model.predict_with_proba(df_input_preds_prep)
    test_class.assertEqual(list(pred_proba[0]), ['non', 'oui'])
    test_class.assertGreater(pred_proba[1][0][index_non], 0.5)
    test_class.assertLess(pred_proba[1][0][index_oui], 0.5)
    test_class.assertGreater(pred_proba[1][1][index_oui], 0.5)
    test_class.assertLess(pred_proba[1][1][index_non], 0.5)
    # get_predict_position
    df_input_get_predict_position = pd.DataFrame({
        'col_1': [-5, 3, 5],
        'col_2': [2, 2, 5],
    })
    df_input_get_predict_position_prep = utils_models.apply_pipeline(df_input_get_predict_position, test_model.preprocess_pipeline)
    # position start at 1
    test_class.assertEqual(list(test_model.get_predict_position(df_input_get_predict_position_prep, ['oui', 'oui', 'toto'])), [2, 1, -1])
    # get_classes_from_proba
    test_class.assertEqual(list(test_model.get_classes_from_proba(probas)), ['non', 'oui'])
    # get_top_n_from_proba
    with test_class.assertRaises(ValueError):
        test_model.get_top_n_from_proba(probas, n=5)  # Only 2 classes in our model
    top_n, top_n_proba = test_model.get_top_n_from_proba(probas, n=2)
    test_class.assertEqual([list(_) for _ in top_n], [['non', 'oui'], ['oui', 'non']])
    test_class.assertEqual([list(_) for _ in top_n_proba], [[probas[0][index_non], probas[0][index_oui]], [probas[1][index_oui], probas[1][index_non]]])
    # inverse_transform
    test_class.assertEqual(list(test_model.inverse_transform(preds)), ['non', 'oui'])

    # Remove dir
    remove_dir(test_model.model_dir)


class Case2_MonoClassMonoLabel(unittest.TestCase):
    '''Class to test the mono-class / mono-label case'''

    def test01_PrepareDatasets(self):
        '''Prepares the datasets'''
        print("Prepares the datasets for mono-class / mono-label case")

        # Clean repo
        pipelines_dir = os.path.join(full_path_lib, 'test_template_num-pipelines')
        models_dir = os.path.join(full_path_lib, 'test_template_num-models')
        if os.path.isdir(pipelines_dir):
            shutil.rmtree(pipelines_dir)
            os.mkdir(pipelines_dir)
        if os.path.isdir(models_dir):
            shutil.rmtree(models_dir)
            os.mkdir(models_dir)

        # Gen. datasets
        split_train_valid_test = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_class_mono_label.csv --split_type random --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col --seed 42"
        preprocessing = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/1_preprocess_data.py -f mono_class_mono_label_train.csv -p preprocess_P1 --target_cols y_col"
        # We don't apply the preprocessing on the validation dataset. We will use the train dataset as validation to simplify
        self.assertEqual(subprocess.run(split_train_valid_test, shell=True).returncode, 0)
        self.assertEqual(subprocess.run(preprocessing, shell=True).returncode, 0)

    def test02_Model_RidgeClassifier(self):
        '''Test of the Ridge Classifier'''
        print('            ------------------ >     Test of the Ridge Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_ridge_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     ridge_params={'alpha': 1.0},
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                     multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_ridge_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                       preprocess_pipeline=preprocess_pipeline,
                                                                       ridge_params={'alpha': 1.0},
                                                                       multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                       multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_ridge_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                          preprocess_pipeline=preprocess_pipeline,
            #                                                          ridge_params={'alpha': 1.0},
            #                                                          multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                          multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_RidgeClassifier failed')

    def test03_Model_LogisticRegressionClassifier(self):
        '''Test of the Logistic Regression Classifier'''
        print('            ------------------ >     Test of the Logistic Regression Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_logistic_regression_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                                                preprocess_pipeline=preprocess_pipeline,
                                                                                                lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
                                                                                                multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                                                multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_logistic_regression_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                                                  preprocess_pipeline=preprocess_pipeline,
                                                                                                  lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
                                                                                                  multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                                                  multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_logistic_regression_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                                                       preprocess_pipeline=preprocess_pipeline,
            #                                                                                       lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
            #                                                                                       multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                                                       multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_LogisticRegressionClassifier failed')

    def test04_Model_SVMClassifier(self):
        '''Test of the Support Vector Machine Classifier'''
        print('            ------------------ >     Test of the Support Vector Machine Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_svm_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 svm_params={'C': 1.0, 'kernel': 'linear'},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_svm_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   svm_params={'C': 1.0, 'kernel': 'linear'},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_svm_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        svm_params={'C': 1.0, 'kernel': 'linear'},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_SVMClassifier failed')

    def test05_Model_SGDClassifier(self):
        '''Test of the Stochastic Gradient Descent Classifier'''
        print('            ------------------ >     Test of the Stochastic Gradient Descent Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_sgd_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_sgd_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_sgd_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_SGDClassifier failed')

    def test06_Model_KNNClassifier(self):
        '''Test of the K-nearest Neighbors Classifier'''
        print('            ------------------ >     Test of the K-nearest Neighbors Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_knn_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_knn_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_knn_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_KNNClassifier failed')

    def test07_Model_RFClassifier(self):
        '''Test of the Random Forest Classifier'''
        print('            ------------------ >     Test of the Random Forest Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_rf_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=preprocess_pipeline,
                                                               rf_params={'n_estimators': 10, 'max_depth': 5},
                                                               multi_label=False, model_name=model_name, model_dir=model_dir,
                                                               multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_rf_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 rf_params={'n_estimators': 10, 'max_depth': 5},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_rf_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                      preprocess_pipeline=preprocess_pipeline,
            #                                                      rf_params={'n_estimators': 10, 'max_depth': 5},
            #                                                      multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                      multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_RFClassifier failed')

    def test08_Model_GBTClassifier(self):
        '''Test of the Gradient Boosted Tree Classifier'''
        print('            ------------------ >     Test of the Gradient Boosted Tree Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_gbt_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
                                                                             'n_estimators': 10, 'subsample': 1.0,
                                                                             'criterion': 'friedman_mse'},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_gbt_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
                                                                               'n_estimators': 10, 'subsample': 1.0,
                                                                               'criterion': 'friedman_mse'},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_gbt_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
            #                                                                    'n_estimators': 10, 'subsample': 1.0,
            #                                                                    'criterion': 'friedman_mse'},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_GBTClassifier failed')

    def test09_Model_XgboostClassifier(self):
        '''Test of the Xgboost'''
        print('            ------------------ >     Test of the Xgboost     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_xgboost_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_xgboost_classifier.ModelXgboostClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                         preprocess_pipeline=preprocess_pipeline,
                                                                         xgboost_params={'n_estimators': 20, 'booster': 'gbtree',
                                                                                         'eta': 0.3, 'gamma': 0, 'max_depth': 6},
                                                                         multi_label=False, model_name=model_name, model_dir=model_dir)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                    filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)
        except Exception:
            self.fail('testModel_XgboostClassifier failed')

    def test10_Model_LGBMClassifier(self):
        '''Test of the Light GBM'''
        print('            ------------------ >     Test of the Light GBM     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_lgbm_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   lgbm_params={'num_leaves': 31, 'max_depth': -1,
                                                                                'learning_rate': 0.1, 'n_estimators': 100},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_lgbm_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     lgbm_params={'num_leaves': 31, 'max_depth': -1,
                                                                                  'learning_rate': 0.1, 'n_estimators': 100},
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                     multiclass_strategy='ovr')
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_mono_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_lgbm_classifier_mono_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                          preprocess_pipeline=preprocess_pipeline,
            #                                                          lgbm_params={'num_leaves': 31, 'max_depth': -1,
            #                                                                       'learning_rate': 0.1, 'n_estimators': 100},
            #                                                          multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                          multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_mono_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_LGBMClassifier failed')

    def test11_Model_DenseClassifier(self):
        '''Test of the Dense Classifier'''
        print('            ------------------ >     Test of the Dense Classifier     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_dense_classifier_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_dense_classifier.ModelDenseClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     batch_size=16, epochs=10, patience=5,
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir)

            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                    filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)

            # Retrieve model & run a second training (continue training)
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            self.assertNotEqual(model_dir, test_model.model_dir)

            # Test second trained model
            test_model_mono_class_mono_label(self, test_model)
        except Exception:
            self.fail('testModel_DenseClassifier failed')

    def test12_Model_Aggregation(self):
        '''Test of the model Aggregation'''
        print('            ------------------ >     Test of the model Aggregation     /   Mono-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_nlp-scripts/2_training.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model with function majority_vote and list_models=[model, model, model]
            model_name = 'aggregation_mono_class_mono_label'
            model_dir_svm1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_svm2 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_gbt = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            list_models = [model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='majority_vote',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function median_predict and list_models=[model_name, model_name, model_name]
            svm1 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            svm2 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col')
            svm2.save()
            gbt = model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')
            gbt.save()

            list_models = [os.path.split(model_dir_svm1)[-1], os.path.split(model_dir_svm2)[-1], os.path.split(model_dir_gbt)[-1]]
            model_name = 'aggregation_mono_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='median_predict',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function mean_predict and list_models=[model_name, model, model]
            model_name = 'aggregation_mono_class_mono_label'
            model_dir_svm1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            svm1 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            list_models = [os.path.split(model_dir_svm1)[-1],
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='mean_predict',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function proba_argmax
            model_name = 'aggregation_mono_class_mono_label'
            list_models = [model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=True, aggregation_function='proba_argmax',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function given
            model_name = 'aggregation_mono_class_mono_label'
            list_models = [model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            # This function is a copy of majority_vote function
            def function_test(predictions: pd.Series) -> list:
                labels, counts = np.unique(predictions, return_counts=True)
                votes = [(label, count) for label, count in zip(labels, counts)]
                votes = sorted(votes, key=lambda x: x[1], reverse=True)
                if len(votes) > 1 and votes[0][1] == votes[1][1]:
                    return predictions[0]
                else:
                    return votes[0][0]
            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function=function_test,
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='mono_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

        except Exception:
            self.fail('testModel_Aggregation failed')


def test_model_mono_class_multi_label(test_class, test_model):
    '''Generic fonction to test a given model for mono-class/multi-labels'''

    # Check if files exist
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, 'configurations.json')))
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, f'{test_model.model_name}.pkl')))
    # Try some functions
    df_input_preds = pd.DataFrame({
        'col_1': [-10, -5, 0, 3],
        'col_2': [-1, 2, -8, 2],
    })
    df_input_preds_prep = utils_models.apply_pipeline(df_input_preds, test_model.preprocess_pipeline)
    index_col_1 = test_model.list_classes.index('y_col_1')
    index_col_2 = test_model.list_classes.index('y_col_2')
    pred_none = [0, 0]
    pred_col_1 = [0, 0]
    pred_col_1[index_col_1] = 1
    pred_col_2 = [0, 0]
    pred_col_2[index_col_2] = 1
    pred_all = [1, 1]
    # predict
    preds = test_model.predict(df_input_preds_prep)
    test_class.assertEqual([list(_) for _ in preds], [pred_none, pred_col_1, pred_col_2, pred_all])
    # predict_proba
    probas = test_model.predict_proba(df_input_preds_prep)
    test_class.assertLess(probas[0][index_col_1], 0.5)
    test_class.assertLess(probas[0][index_col_2], 0.5)
    test_class.assertGreater(probas[1][index_col_1], 0.5)
    test_class.assertLess(probas[1][index_col_2], 0.5)
    test_class.assertLess(probas[2][index_col_1], 0.5)
    test_class.assertGreater(probas[2][index_col_2], 0.5)
    test_class.assertGreater(probas[3][index_col_1], 0.5)
    test_class.assertGreater(probas[3][index_col_2], 0.5)
    # predict w/ return_proba=True
    probas2 = test_model.predict(df_input_preds_prep, return_proba=True)
    test_class.assertLess(probas2[0][index_col_1], 0.5)
    test_class.assertLess(probas2[0][index_col_2], 0.5)
    test_class.assertGreater(probas2[1][index_col_1], 0.5)
    test_class.assertLess(probas2[1][index_col_2], 0.5)
    test_class.assertLess(probas2[2][index_col_1], 0.5)
    test_class.assertGreater(probas2[2][index_col_2], 0.5)
    test_class.assertGreater(probas2[3][index_col_1], 0.5)
    test_class.assertGreater(probas2[3][index_col_2], 0.5)
    # predict_with_proba
    pred_proba = test_model.predict_with_proba(df_input_preds_prep)
    test_class.assertEqual([list(_) for _ in pred_proba[0]], [pred_none, pred_col_1, pred_col_2, pred_all])
    test_class.assertLess(pred_proba[1][0][index_col_1], 0.5)
    test_class.assertLess(pred_proba[1][0][index_col_2], 0.5)
    test_class.assertGreater(pred_proba[1][1][index_col_1], 0.5)
    test_class.assertLess(pred_proba[1][1][index_col_2], 0.5)
    test_class.assertLess(pred_proba[1][2][index_col_1], 0.5)
    test_class.assertGreater(pred_proba[1][2][index_col_2], 0.5)
    test_class.assertGreater(pred_proba[1][3][index_col_1], 0.5)
    test_class.assertGreater(pred_proba[1][3][index_col_2], 0.5)
    # get_predict_position
    # position start at 1
    with test_class.assertRaises(ValueError):
        test_model.get_predict_position(df_input_preds_prep, ['toto', 'tata', 'toto', 'titi'])  # Does not work with multi-labels
    # get_classes_from_proba
    test_class.assertEqual([list(_) for _ in test_model.get_classes_from_proba(probas)], [pred_none, pred_col_1, pred_col_2, pred_all])
    # get_top_n_from_proba
    with test_class.assertRaises(ValueError):
        test_model.get_top_n_from_proba(probas, n=2)  # Does not work with multi-labels
    # inverse_transform
    test_class.assertEqual(list(test_model.inverse_transform(preds)), [(), ('y_col_1',), ('y_col_2',), ('y_col_1', 'y_col_2')])

    # Remove dir
    remove_dir(test_model.model_dir)


class Case3_MonoClassMultiLabel(unittest.TestCase):
    '''Class to test the mono-class / multi-labels case'''

    def test01_PrepareDatasets(self):
        '''Prepares the datasets'''
        print("Prepares the datasets for the mono-class / multi-labels case")

        # Clean repo
        pipelines_dir = os.path.join(full_path_lib, 'test_template_num-pipelines')
        models_dir = os.path.join(full_path_lib, 'test_template_num-models')
        if os.path.isdir(pipelines_dir):
            shutil.rmtree(pipelines_dir)
            os.mkdir(pipelines_dir)
        if os.path.isdir(models_dir):
            shutil.rmtree(models_dir)
            os.mkdir(models_dir)

        # Gen. datasets
        split_train_valid_test = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_class_multi_label.csv --split_type random --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col_1 --seed 42"
        preprocessing = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/1_preprocess_data.py -f mono_class_multi_label_train.csv -p preprocess_P1 --target_cols y_col_1 y_col_2"
        # We don't apply the preprocessing on the validation dataset. We will use the train dataset as validation to simplify
        self.assertEqual(subprocess.run(split_train_valid_test, shell=True).returncode, 0)
        self.assertEqual(subprocess.run(preprocessing, shell=True).returncode, 0)

    def test02_Model_RidgeClassifier(self):
        '''Test of the Ridge Classifier'''
        print('            ------------------ >     Test of the Ridge Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_ridge_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     ridge_params={'alpha': 0.01, 'solver': 'lsqr'},
                                                                     multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                     multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_RidgeClassifier failed')

    def test03_Model_LogisticRegressionClassifier(self):
        '''Test of the Logistic Regression Classifier'''
        print('            ------------------ >     Test of the Logistic Regression Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_logistic_regression_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                                                preprocess_pipeline=preprocess_pipeline,
                                                                                                lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
                                                                                                multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                                                multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_LogisticRegressionClassifier failed')

    def test04_Model_SVMClassifier(self):
        '''Test of the Support Vector Machine Classifier'''
        print('            ------------------ >     Test of the Support Vector Machine Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_svm_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 svm_params={'C': 1.0, 'kernel': 'linear'},
                                                                 multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_SVMClassifier failed')

    def test05_Model_SGDClassifier(self):
        '''Test of the Stochastic Gradient Descent Classifier'''
        print('            ------------------ >     Test of the Stochastic Gradient Descent Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_sgd_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
                                                                 multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_SGDClassifier failed')

    def test06_Model_KNNClassifier(self):
        '''Test of the K-nearest Neighbors Classifier'''
        print('            ------------------ >     Test of the K-nearest Neighbors Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_knn_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
                                                                 multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_KNNClassifier failed')

    def test07_Model_RFClassifier(self):
        '''Test of the Random Forest Classifier'''
        print('            ------------------ >     Test of the Random Forest Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_rf_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                               preprocess_pipeline=preprocess_pipeline,
                                                               rf_params={'n_estimators': 10, 'max_depth': 5},
                                                               multi_label=True, model_name=model_name, model_dir=model_dir,
                                                               multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_RFClassifier failed')

    def test08_Model_GBTClassifier(self):
        '''Test of the Gradient Boosted Tree Classifier'''
        print('            ------------------ >     Test of the Gradient Boosted Tree Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_gbt_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
                                                                             'n_estimators': 10, 'subsample': 1.0,
                                                                             'criterion': 'friedman_mse'},
                                                                 multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_GBTClassifier failed')

    def test09_Model_XgboostClassifier(self):
        '''Test of the Xgboost'''
        print('            ------------------ >     Test of the Xgboost     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_xgboost_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_xgboost_classifier.ModelXgboostClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                         preprocess_pipeline=preprocess_pipeline,
                                                                         xgboost_params={'n_estimators': 20, 'booster': 'gbtree',
                                                                                         'eta': 0.3, 'gamma': 0, 'max_depth': 6},
                                                                         multi_label=True, model_name=model_name, model_dir=model_dir)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_XgboostClassifier failed')

    def test10_Model_LGBMClassifier(self):
        '''Test of the Light GBM'''
        print('            ------------------ >     Test of the Light GBM     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_lgbm_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   lgbm_params={'num_leaves': 31, 'max_depth': -1,
                                                                                'learning_rate': 0.1, 'n_estimators': 100},
                                                                   multi_label=True, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy=None)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_LGBMClassifier failed')

    def test11_Model_DenseClassifier(self):
        '''Test of the Dense Classifier'''
        print('            ------------------ >     Test of the Dense Classifier     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_dense_classifier_mono_class_multi_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_dense_classifier.ModelDenseClassifier(x_col=['col_1', 'col_2'], y_col=['y_col_1', 'y_col_2'], level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     batch_size=16, epochs=50, patience=5,
                                                                     multi_label=True, model_name=model_name, model_dir=model_dir)

            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)

            # Retrieve model & run a second training (continue training)
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            self.assertNotEqual(model_dir, test_model.model_dir)

            # Test second trained model
            test_model_mono_class_multi_label(self, test_model)
        except Exception:
            self.fail('testModel_DenseClassifier failed')

    def test12_Model_Aggregation(self):
        '''Test of the model Aggregation'''
        print('            ------------------ >     Test of the model Aggregation     /   Mono-class & Multi-labels')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_nlp-scripts/2_training.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model function all_predictions and list_models=[model, model, model]
            model_name = 'aggregation_mono_class_multi_label'
            model_dir_svm1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_svm2 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_gbt = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            list_models = [model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(multi_label=True, model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='all_predictions',
                                                            multi_label=True, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function all_predictions and list_models=[model_name, model_name, model_name]
            model_name = 'aggregation_mono_class_multi_label'
            svm1 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, multi_label=True, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            svm2 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, multi_label=True, x_col=['col_1', 'col_2'], y_col='y_col')
            svm2.save()
            gbt = model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, multi_label=True, x_col=['col_1', 'col_2'], y_col='y_col')
            gbt.save()

            list_models = [os.path.split(model_dir_svm1)[-1], os.path.split(model_dir_svm2)[-1], os.path.split(model_dir_gbt)[-1]]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='all_predictions',
                                                            multi_label=True, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function all_predictions and list_models=[model_name, model, model]
            model_name = 'aggregation_mono_class_multi_label'
            svm1 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, multi_label=True, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            list_models = [os.path.split(model_dir_svm1)[-1],
                           model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(multi_label=True, model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='all_predictions',
                                                            multi_label=True, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function vote_labels
            model_name = 'aggregation_mono_class_multi_label'
            list_models = [model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(multi_label=True, model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='vote_labels',
                                                            multi_label=True, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function given
            model_name = 'aggregation_mono_class_multi_label'
            list_models = [model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(multi_label=True, model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(multi_label=True, model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            # This function is a copy of all_predictions function
            def function_test(predictions: pd.Series) -> list:
                return np.sum(predictions, axis=0, dtype=bool).astype(int)


            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function=function_test,
                                                            multi_label=True, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='mono_class_multi_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col_1', 'y_col_2'],
                      filename_valid='mono_class_multi_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_class_multi_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

        except Exception:
            self.fail('testModel_Aggregation failed')


def test_model_multi_class_mono_label(test_class, test_model):
    '''Generic fonction to test a given model for multi-classes/mono-label'''

    # Check if files exist
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, 'configurations.json')))
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, f'{test_model.model_name}.pkl')))
    # Try some functions
    df_input_preds = pd.DataFrame({
        'col_1': [12, -6, 5, -10],
        'col_2': [6, 12, -6, -5],
    })
    df_input_preds_prep = utils_models.apply_pipeline(df_input_preds, test_model.preprocess_pipeline)
    index_none = test_model.list_classes.index('none')
    index_a = test_model.list_classes.index('a')
    index_b = test_model.list_classes.index('b')
    index_both = test_model.list_classes.index('both')
    pred_none = [0, 0, 0, 0]
    pred_none[index_none] = 1
    pred_a = [0, 0, 0, 0]
    pred_a[index_a] = 1
    pred_b = [0, 0, 0, 0]
    pred_b[index_b] = 1
    pred_both = [0, 0, 0, 0]
    pred_both[index_both] = 1
    # predict
    preds = test_model.predict(df_input_preds_prep)
    test_class.assertEqual(list(preds), ['none', 'a', 'b', 'both'])
    # predict_proba
    probas = test_model.predict_proba(df_input_preds_prep)
    test_class.assertEqual(round(probas.sum(), 3), 4.)  # We round for deep learning models
    test_class.assertGreater(probas[0][index_none], 1/4)
    test_class.assertLess(probas[0][index_a], probas[0][index_none])
    test_class.assertLess(probas[0][index_b], probas[0][index_none])
    test_class.assertLess(probas[0][index_both], probas[0][index_none])
    test_class.assertLess(probas[1][index_none], probas[1][index_a])
    test_class.assertGreater(probas[1][index_a], 1/4)
    test_class.assertLess(probas[1][index_b], probas[1][index_a])
    test_class.assertLess(probas[1][index_both], probas[1][index_a])
    test_class.assertLess(probas[2][index_none], probas[2][index_b])
    test_class.assertLess(probas[2][index_a], probas[2][index_b])
    test_class.assertGreater(probas[2][index_b], 1/4)
    test_class.assertLess(probas[2][index_both], probas[2][index_b])
    test_class.assertLess(probas[3][index_none], probas[3][index_both])
    test_class.assertLess(probas[3][index_a], probas[3][index_both])
    test_class.assertLess(probas[3][index_b], probas[3][index_both])
    test_class.assertGreater(probas[3][index_both], 1/4)
    # predict w/ return_proba=True
    probas2 = test_model.predict(df_input_preds_prep, return_proba=True)
    test_class.assertEqual(round(probas2.sum(), 3), 4.)  # We round for deep learning models
    test_class.assertGreater(probas2[0][index_none], 1/4)
    test_class.assertLess(probas2[0][index_a], probas2[0][index_none])
    test_class.assertLess(probas2[0][index_b], probas2[0][index_none])
    test_class.assertLess(probas2[0][index_both], probas2[0][index_none])
    test_class.assertLess(probas2[1][index_none], probas2[1][index_a])
    test_class.assertGreater(probas2[1][index_a], 1/4)
    test_class.assertLess(probas2[1][index_b], probas2[1][index_a])
    test_class.assertLess(probas2[1][index_both], probas2[1][index_a])
    test_class.assertLess(probas2[2][index_none], probas2[2][index_b])
    test_class.assertLess(probas2[2][index_a], probas2[2][index_b])
    test_class.assertGreater(probas2[2][index_b], 1/4)
    test_class.assertLess(probas2[2][index_both], probas2[2][index_b])
    test_class.assertLess(probas2[3][index_none], probas2[3][index_both])
    test_class.assertLess(probas2[3][index_a], probas2[3][index_both])
    test_class.assertLess(probas2[3][index_b], probas2[3][index_both])
    test_class.assertGreater(probas2[3][index_both], 1/4)
    # predict_with_proba
    pred_proba = test_model.predict_with_proba(df_input_preds_prep)
    test_class.assertEqual(list(pred_proba[0]), ['none', 'a', 'b', 'both'])
    test_class.assertEqual(round(pred_proba[1].sum(), 3), 4.)  # We round for deep learning models
    test_class.assertGreater(pred_proba[1][0][index_none], 1/4)
    test_class.assertLess(pred_proba[1][0][index_a], pred_proba[1][0][index_none])
    test_class.assertLess(pred_proba[1][0][index_b], pred_proba[1][0][index_none])
    test_class.assertLess(pred_proba[1][0][index_both], pred_proba[1][0][index_none])
    test_class.assertLess(pred_proba[1][1][index_none], pred_proba[1][1][index_a])
    test_class.assertGreater(pred_proba[1][1][index_a], 1/4)
    test_class.assertLess(pred_proba[1][1][index_b], pred_proba[1][1][index_a])
    test_class.assertLess(pred_proba[1][1][index_both], pred_proba[1][1][index_a])
    test_class.assertLess(pred_proba[1][2][index_none], pred_proba[1][2][index_b])
    test_class.assertLess(pred_proba[1][2][index_a], pred_proba[1][2][index_b])
    test_class.assertGreater(pred_proba[1][2][index_b], 1/4)
    test_class.assertLess(pred_proba[1][2][index_both], pred_proba[1][2][index_b])
    test_class.assertLess(pred_proba[1][3][index_none], pred_proba[1][3][index_both])
    test_class.assertLess(pred_proba[1][3][index_a], pred_proba[1][3][index_both])
    test_class.assertLess(pred_proba[1][3][index_b], pred_proba[1][3][index_both])
    test_class.assertGreater(pred_proba[1][3][index_both], 1/4)
    # get_predict_position
    df_input_get_predict_position = pd.DataFrame({
        'col_1': [12, -6, 5, -10, 5],
        'col_2': [6, 12, -6, -5, 9],
    })
    df_input_get_predict_position_prep = utils_models.apply_pipeline(df_input_get_predict_position, test_model.preprocess_pipeline)
    # position start at 1
    predict_pos = test_model.get_predict_position(df_input_get_predict_position_prep, ['none', 'a', 'a', 'both', 'toto'])
    test_class.assertEqual(list(predict_pos[[0, 1, 3, 4]]), [1, 1, 1, -1])
    test_class.assertGreater(predict_pos[2], 1)
    # get_classes_from_proba
    test_class.assertEqual(list(test_model.get_classes_from_proba(probas)), ['none', 'a', 'b', 'both'])
    # get_top_n_from_proba
    with test_class.assertRaises(ValueError):
        test_model.get_top_n_from_proba(probas, n=5)  # Only 4 classes in our model
    top_n, top_n_proba = test_model.get_top_n_from_proba(probas, n=4)
    test_class.assertEqual([_[0] for _ in top_n], ['none', 'a', 'b', 'both'])
    test_class.assertEqual(sorted(top_n[0]), sorted(['none', 'a', 'b', 'both']))
    test_class.assertEqual(sorted(top_n[1]), sorted(['none', 'a', 'b', 'both']))
    test_class.assertEqual(sorted(top_n[2]), sorted(['none', 'a', 'b', 'both']))
    test_class.assertEqual(sorted(top_n[3]), sorted(['none', 'a', 'b', 'both']))
    test_class.assertEqual([_[0] for _ in top_n_proba], [probas[0][index_none], probas[1][index_a], probas[2][index_b], probas[3][index_both]])
    # inverse_transform
    test_class.assertEqual(list(test_model.inverse_transform(preds)), ['none', 'a', 'b', 'both'])

    # Remove dir
    remove_dir(test_model.model_dir)


class Case4_MultiClassMonoLabel(unittest.TestCase):
    '''Class to test the multi-classes / mono-label case'''

    def test01_PrepareDatasets(self):
        '''Prepares the datasets'''
        print("Prepares the datasets for the multi-classes / mono-label case")

        # Clean repo
        pipelines_dir = os.path.join(full_path_lib, 'test_template_num-pipelines')
        models_dir = os.path.join(full_path_lib, 'test_template_num-models')
        if os.path.isdir(pipelines_dir):
            shutil.rmtree(pipelines_dir)
            os.mkdir(pipelines_dir)
        if os.path.isdir(models_dir):
            shutil.rmtree(models_dir)
            os.mkdir(models_dir)

        # Gen. datasets
        split_train_valid_test = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f multi_class_mono_label.csv --split_type random --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col --seed 42"
        preprocessing = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/1_preprocess_data.py -f multi_class_mono_label_train.csv -p preprocess_P1 --target_cols y_col"
        # We don't apply the preprocessing on the validation dataset. We will use the train dataset as validation to simplify
        self.assertEqual(subprocess.run(split_train_valid_test, shell=True).returncode, 0)
        self.assertEqual(subprocess.run(preprocessing, shell=True).returncode, 0)

    def test02_Model_RidgeClassifier(self):
        '''Test of the Ridge Classifier'''
        print('            ------------------ >     Test of the Ridge Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_ridge_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     ridge_params={'alpha': 1.0},
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                     multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_ridge_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     ridge_params={'alpha': 1.0},
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                     multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_ridge_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_ridge_classifier.ModelRidgeClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                          preprocess_pipeline=preprocess_pipeline,
            #                                                          ridge_params={'alpha': 1.0},
            #                                                          multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                          multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_RidgeClassifier failed')

    def test03_Model_LogisticRegressionClassifier(self):
        '''Test of the Logistic Regression Classifier'''
        print('            ------------------ >     Test of the Logistic Regression Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_logistic_regression_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                                                preprocess_pipeline=preprocess_pipeline,
                                                                                                lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
                                                                                                multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                                                multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_logistic_regression_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                                                  preprocess_pipeline=preprocess_pipeline,
                                                                                                  lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
                                                                                                  multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                                                  multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_logistic_regression_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_logistic_regression_classifier.ModelLogisticRegressionClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                                                       preprocess_pipeline=preprocess_pipeline,
            #                                                                                       lr_params={'penalty': 'l2', 'C': 1.0, 'max_iter': 100},
            #                                                                                       multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                                                       multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_LogisticRegressionClassifier failed')

    def test04_Model_SVMClassifier(self):
        '''Test of the Support Vector Machine Classifier'''
        print('            ------------------ >     Test of the Support Vector Machine Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_svm_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 svm_params={'C': 1.0, 'kernel': 'linear'},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_svm_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   svm_params={'C': 1.0, 'kernel': 'linear'},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_svm_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_svm_classifier.ModelSVMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        svm_params={'C': 1.0, 'kernel': 'linear'},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_SVMClassifier failed')

    def test05_Model_SGDClassifier(self):
        '''Test of the Stochastic Gradient Descent Classifier'''
        print('            ------------------ >     Test of the Stochastic Gradient Descent Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_sgd_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_sgd_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_sgd_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_sgd_classifier.ModelSGDClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        sgd_params={'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_SGDClassifier failed')

    def test06_Model_KNNClassifier(self):
        '''Test of the K-nearest Neighbors Classifier'''
        print('            ------------------ >     Test of the K-nearest Neighbors Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_knn_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_knn_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_knn_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_knn_classifier.ModelKNNClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        knn_params={'n_neighbors': 1, 'algorithm': 'brute'},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_KNNClassifier failed')

    def test07_Model_RFClassifier(self):
        '''Test of the Random Forest Classifier'''
        print('            ------------------ >     Test of the Random Forest Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_rf_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=preprocess_pipeline,
                                                               rf_params={'n_estimators': 10, 'max_depth': 5},
                                                               multi_label=False, model_name=model_name, model_dir=model_dir,
                                                               multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_rf_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 rf_params={'n_estimators': 10, 'max_depth': 5},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_rf_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_rf_classifier.ModelRFClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                      preprocess_pipeline=preprocess_pipeline,
            #                                                      rf_params={'n_estimators': 10, 'max_depth': 5},
            #                                                      multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                      multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_RFClassifier failed')

    def test08_Model_GBTClassifier(self):
        '''Test of the Gradient Boosted Tree Classifier'''
        print('            ------------------ >     Test of the Gradient Boosted Tree Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_gbt_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                 preprocess_pipeline=preprocess_pipeline,
                                                                 gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
                                                                             'n_estimators': 10, 'subsample': 1.0,
                                                                             'criterion': 'friedman_mse'},
                                                                 multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                 multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_gbt_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
                                                                               'n_estimators': 10, 'subsample': 1.0,
                                                                               'criterion': 'friedman_mse'},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_gbt_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_gbt_classifier.ModelGBTClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                        preprocess_pipeline=preprocess_pipeline,
            #                                                        gbt_params={'loss': 'deviance', 'learning_rate': 0.1,
            #                                                                    'n_estimators': 10, 'subsample': 1.0,
            #                                                                    'criterion': 'friedman_mse'},
            #                                                        multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                        multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_GBTClassifier failed')

    def test09_Model_XgboostClassifier(self):
        '''Test of the Xgboost'''
        print('            ------------------ >     Test of the Xgboost     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_xgboost_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_xgboost_classifier.ModelXgboostClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                         preprocess_pipeline=preprocess_pipeline,
                                                                         xgboost_params={'n_estimators': 20, 'booster': 'gbtree',
                                                                                         'eta': 0.3, 'gamma': 0, 'max_depth': 6},
                                                                         multi_label=False, model_name=model_name, model_dir=model_dir)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                    filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)
        except Exception:
            self.fail('testModel_XgboostClassifier failed')

    def test10_Model_LGBMClassifier(self):
        '''Test of the Light GBM'''
        print('            ------------------ >     Test of the Light GBM     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_lgbm_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=preprocess_pipeline,
                                                                   lgbm_params={'num_leaves': 31, 'max_depth': -1,
                                                                                'learning_rate': 0.1, 'n_estimators': 100},
                                                                   multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                   multiclass_strategy=None)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Set second model
            model_name = 'model_lgbm_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model_2 = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     lgbm_params={'num_leaves': 31, 'max_depth': -1,
                                                                                  'learning_rate': 0.1, 'n_estimators': 100},
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir,
                                                                     multiclass_strategy='ovr')
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_2)
            test_model_multi_class_mono_label(self, test_model_2)

            # Set third model
            # 'ovo' instable
            # model_name = 'model_lgbm_classifier_multi_class_mono_label'
            # model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            # os.makedirs(model_dir)
            # test_model_3 = model_lgbm_classifier.ModelLGBMClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
            #                                                          preprocess_pipeline=preprocess_pipeline,
            #                                                          lgbm_params={'num_leaves': 31, 'max_depth': -1,
            #                                                                       'learning_rate': 0.1, 'n_estimators': 100},
            #                                                          multi_label=False, model_name=model_name, model_dir=model_dir,
            #                                                          multiclass_strategy='ovo')
            # # Test it
            # test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
            #           filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model_3)
            # test_model_multi_class_mono_label(self, test_model_3)
        except Exception:
            self.fail('testModel_LGBMClassifier failed')

    def test11_Model_DenseClassifier(self):
        '''Test of the Dense Classifier'''
        print('            ------------------ >     Test of the Dense Classifier     /   Multi-classes & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_classification.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Get pipeline
            pipelines_dirpath = os.path.join(full_path_lib, 'test_template_num-pipelines')
            pipeline_name = os.listdir(pipelines_dirpath)[0]
            preprocess_pipeline, _ = utils_models.load_pipeline(pipeline_name)

            # Set model
            model_name = 'model_dense_classifier_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_dense_classifier.ModelDenseClassifier(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                     preprocess_pipeline=preprocess_pipeline,
                                                                     batch_size=16, epochs=10, patience=5,
                                                                     multi_label=False, model_name=model_name, model_dir=model_dir)

            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                    filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)

            # Retrieve model & run a second training (continue training)
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            self.assertNotEqual(model_dir, test_model.model_dir)

            # Test second trained model
            test_model_multi_class_mono_label(self, test_model)
        except Exception:
            self.fail('testModel_DenseClassifier failed')

    def test12_Model_Aggregation(self):
        '''Test of the model Aggregation'''
        print('            ------------------ >     Test of the model Aggregation     /   Multi-class & Mono-label')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_nlp-scripts/2_training.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model with function majority_vote and list_models=[model, model, model]
            model_name = 'aggregation_multi_class_mono_label'
            model_dir_svm1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_svm2 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_gbt = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            list_models = [model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='majority_vote',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function median_predict and list_models=[model_name, model_name, model_name]
            svm1 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            svm2 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col')
            svm2.save()
            gbt = model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')
            gbt.save()

            list_models = [os.path.split(model_dir_svm1)[-1], os.path.split(model_dir_svm2)[-1], os.path.split(model_dir_gbt)[-1]]
            model_name = 'aggregation_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='median_predict',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function mean_predict and list_models=[model_name, model, model]
            model_name = 'aggregation_multi_class_mono_label'
            model_dir_svm1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            svm1 = model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            list_models = [os.path.split(model_dir_svm1)[-1],
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='mean_predict',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function proba_argmax
            model_name = 'aggregation_multi_class_mono_label'
            list_models = [model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=True, aggregation_function='proba_argmax',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

            # Set model with function given
            model_name = 'aggregation_multi_class_mono_label'
            list_models = [model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_svm_classifier.ModelSVMClassifier(model_dir=model_dir_svm2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_classifier.ModelGBTClassifier(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            # This function is a copy of majority_vote function
            def function_test(predictions: pd.Series) -> list:
                labels, counts = np.unique(predictions, return_counts=True)
                votes = [(label, count) for label, count in zip(labels, counts)]
                votes = sorted(votes, key=lambda x: x[1], reverse=True)
                if len(votes) > 1 and votes[0][1] == votes[1][1]:
                    return predictions[0]
                else:
                    return votes[0][0]

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function=function_test,
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_multi_class_mono_label(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_svm1)
            remove_dir(model_dir_svm2)
            remove_dir(model_dir_gbt)

        except Exception:
            self.fail('testModel_Aggregation failed')


def test_model_mono_output_regression(test_class, test_model):
    '''Generic fonction to test a given model for mono-output regression'''

    # Check if files exist
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, 'configurations.json')))
    test_class.assertTrue(os.path.exists(os.path.join(test_model.model_dir, f'{test_model.model_name}.pkl')))
    # Try some functions
    df_input_preds = pd.DataFrame({
        'col_1': [-5, 3],
        'col_2': [2, 2],
    })
    df_input_preds_prep = utils_models.apply_pipeline(df_input_preds, test_model.preprocess_pipeline)
    # predict
    preds = test_model.predict(df_input_preds_prep)
    test_class.assertGreater(preds[0], -4)  # should predict -3, test > -4 ...
    test_class.assertLess(preds[0], -2)  # ... and < -2
    test_class.assertGreater(preds[1], 4)  # should predict 5, test > 4 ...
    test_class.assertLess(preds[1], 6)  # ... and < 6
    # predict_proba
    with test_class.assertRaises(ValueError):
        probas = test_model.predict_proba(df_input_preds_prep)
    # predict w/ return_proba=True
    with test_class.assertRaises(ValueError):
        probas2 = test_model.predict(df_input_preds_prep, return_proba=True)
    # inverse_transform
    test_class.assertEqual(list(test_model.inverse_transform(preds)), list(preds))

    # Remove dir
    remove_dir(test_model.model_dir)


class Case5_MonoOutputRegression(unittest.TestCase):
    '''Class to test the mono-output regression case'''

    def test01_PrepareDatasets(self):
        '''Prepares the datasets'''
        print("Prepares the datasets for the mono-output regression case")

        # Clean repo
        pipelines_dir = os.path.join(full_path_lib, 'test_template_num-pipelines')
        models_dir = os.path.join(full_path_lib, 'test_template_num-models')
        if os.path.isdir(pipelines_dir):
            shutil.rmtree(pipelines_dir)
            os.mkdir(pipelines_dir)
        if os.path.isdir(models_dir):
            shutil.rmtree(models_dir)
            os.mkdir(models_dir)

        # Gen. datasets
        split_train_valid_test = f"{activate_venv}python {full_path_lib}/test_template_num-scripts/utils/0_split_train_valid_test.py --overwrite -f mono_output_regression.csv --split_type random --perc_train 0.6 --perc_valid 0.2 --perc_test 0.2 --y_col y_col --seed 42"
        self.assertEqual(subprocess.run(split_train_valid_test, shell=True).returncode, 0)

    def test02_Model_ElasticNetRegressor(self):
        '''Test of the Elastic Net'''
        print('            ------------------ >     Test of the Elastic Net     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)


            # Set model
            model_name = 'model_elasticnet_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_elasticnet_regressor.ModelElasticNetRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                             preprocess_pipeline=None,
                                                                             elasticnet_params={'alpha': 0.01, 'l1_ratio': 0.5},
                                                                             model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_ElasticNetRegressor failed')

    def test03_Model_BayesianRidgeRegressor(self):
        '''Test of the Linear Regression'''
        print('            ------------------ >     Test of the Linear Regression     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_bayesian_ridge_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_bayesian_ridge_regressor.ModelBayesianRidgeRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                                    preprocess_pipeline=None,
                                                                                    bayesian_ridge_params={'n_iter': 300},
                                                                                    model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_BayesianRidgeRegressor failed')

    def test04_Model_KernelRidgeRegressor(self):
        '''Test of the Kernel Ridge'''
        print('            ------------------ >     Test of the Kernel Ridge     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_kernel_ridge_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_kernel_ridge_regressor.ModelKernelRidgeRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                                preprocess_pipeline=None,
                                                                                kernel_ridge_params={'alpha': 1.0, 'kernel': 'linear'},
                                                                                model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_KernelRidgeRegressor failed')

    def test05_Model_SVRRegressor(self):
        '''Test of the Support Vector Regression'''
        print('            ------------------ >     Test of the Support Vector Regression     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_svr_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_svr_regressor.ModelSVRRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               svr_params={'kernel': 'linear'},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_SVRRegressor failed')

    def test06_Model_SGDRegressor(self):
        '''Test of the Stochastic Gradient Descent'''
        print('            ------------------ >     Test of the Stochastic Gradient Descent     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_sgd_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_sgd_regressor.ModelSGDRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               sgd_params={'loss': 'squared_loss', 'penalty': 'elasticnet', 'l1_ratio': 0.5},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_SGDRegressor failed')

    def test07_Model_KNNRegressor(self):
        '''Test of the K-nearest Neighbors'''
        print('            ------------------ >     Test of the K-nearest Neighbors     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_knn_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_knn_regressor.ModelKNNRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               knn_params={'n_neighbors': 7, 'weights': 'distance'},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_KNNRegressor failed')

    def test08_Model_PLSRegressor(self):
        '''Test of the Partial Least Squares'''
        print('            ------------------ >     Test of the Partial Least Squares     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_pls_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_pls_regressor.ModelPLSRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               pls_params={'n_components': 2, 'max_iter': 500},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_PLSRegressor failed')

    def test09_Model_RFRegressor(self):
        '''Test of the Random Forest'''
        print('            ------------------ >     Test of the Random Forest     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_rf_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_rf_regressor.ModelRFRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                             preprocess_pipeline=None,
                                                             rf_params={'n_estimators': 50, 'max_depth': 5},
                                                             model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_RFRegressor failed')

    def test10_Model_GBTRegressor(self):
        '''Test of the Gradient Boosting Tree'''
        print('            ------------------ >     Test of the Gradient Boosting Tree     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_gbt_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_gbt_regressor.ModelGBTRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               gbt_params={'loss': 'ls', 'learning_rate': 0.1,
                                                                           'n_estimators': 100, 'subsample': 1.0,
                                                                           'criterion': 'friedman_mse'},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_GBTRegressor failed')

    def test11_Model_XgboostRegressor(self):
        '''Test of the Xgboost'''
        print('            ------------------ >     Test of the Xgboost     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_xgboost_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_xgboost_regressor.ModelXgboostRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               xgboost_params={'n_estimators': 20, 'booster': 'gbtree',
                                                                               'eta': 0.3, 'gamma': 0, 'max_depth': 6},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_XgboostRegressor failed')

    def test12_Model_LGBMRegressor(self):
        '''Test of the Light GBM'''
        print('            ------------------ >     Test of the Light GBM     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_lgbm_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_lgbm_regressor.ModelLGBMRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                               preprocess_pipeline=None,
                                                               lgbm_params={'num_leaves': 31, 'max_depth': -1,
                                                                            'learning_rate': 0.1, 'n_estimators': 100},
                                                               model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_LGBMRegressor failed')

    def test13_Model_DenseRegressor(self):
        '''Test of the Dense'''
        print('            ------------------ >     Test of the Dense     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_num-scripts/3_training_regression.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model
            model_name = 'model_dense_regressor_mono_output_regression'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            os.makedirs(model_dir)
            test_model = model_dense_regressor.ModelDenseRegressor(x_col=['col_1', 'col_2'], y_col='y_col', level_save='HIGH',
                                                                   preprocess_pipeline=None,
                                                                   batch_size=16, epochs=50, patience=5,
                                                                   model_name=model_name, model_dir=model_dir)

            # Test it (directly on the file with no preprocessing)
            test.main(filename='mono_output_regression_train.csv', y_col='y_col',
                      filename_valid='mono_output_regression_train.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
        except Exception:
            self.fail('testModel_DenseRegressor failed')

    def test14_Model_Aggregation(self):
        '''Test of the model Aggregation'''
        print('            ------------------ >     Test of the model Aggregation     /   Mono-output Regression')

        try:
            # Load training file
            spec = importlib.util.spec_from_file_location("test", f'{full_path_lib}/test_template_nlp-scripts/2_training.py')
            test = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(test)

            # Set model with function majority_vote and list_models=[model, model, model]
            model_name = 'aggregation_multi_class_mono_label'
            model_dir_sgd1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_sgd2 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir_gbt = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            list_models = [model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_regressor.ModelGBTRegressor(model_dir=model_dir_sgd2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_regressor.ModelGBTRegressor(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='majority_vote',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_sgd1)
            remove_dir(model_dir_sgd2)
            remove_dir(model_dir_gbt)

            # Set model with function majority_vote and list_models=[model_name, model_name, model_name]
            svm1 = model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd1, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            svm2 = model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd2, x_col=['col_1', 'col_2'], y_col='y_col')
            svm2.save()
            gbt = model_gbt_regressor.ModelGBTRegressor(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')
            gbt.save()

            list_models = [os.path.split(model_dir_sgd1)[-1], os.path.split(model_dir_sgd2)[-1], os.path.split(model_dir_gbt)[-1]]
            model_name = 'aggregation_multi_class_mono_label'
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='majority_vote',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_sgd1)
            remove_dir(model_dir_sgd2)
            remove_dir(model_dir_gbt)

            # Set model with function mean_predict and list_models=[model_name, model, model]
            model_name = 'aggregation_multi_class_mono_label'
            model_dir_sgd1 = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))
            svm1 = model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd1, x_col=['col_1', 'col_2'], y_col='y_col')
            svm1.save()
            list_models = [os.path.split(model_dir_sgd1)[-1],
                           model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_regressor.ModelGBTRegressor(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='mean_predict',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_sgd1)
            remove_dir(model_dir_sgd2)
            remove_dir(model_dir_gbt)

            # Set model with function median_predict
            model_name = 'aggregation_multi_class_mono_label'
            list_models = [model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_regressor.ModelGBTRegressor(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function='median_predict',
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_sgd1)
            remove_dir(model_dir_sgd2)
            remove_dir(model_dir_gbt)

            # Set model with function given
            model_name = 'aggregation_multi_class_mono_label'
            list_models = [model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd1, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_sgd_regressor.ModelSGDRegressor(model_dir=model_dir_sgd2, x_col=['col_1', 'col_2'], y_col='y_col'),
                           model_gbt_regressor.ModelGBTRegressor(model_dir=model_dir_gbt, x_col=['col_1', 'col_2'], y_col='y_col')]
            model_dir = os.path.join(utils.get_models_path(), model_name, datetime.now().strftime(f"{model_name}_%Y_%m_%d-%H_%M_%S"))

            # This function is a copy of majority_vote function
            def function_test(predictions: pd.Series) -> list:
                labels, counts = np.unique(predictions, return_counts=True)
                votes = [(label, count) for label, count in zip(labels, counts)]
                votes = sorted(votes, key=lambda x: x[1], reverse=True)
                if len(votes) > 1 and votes[0][1] == votes[1][1]:
                    return predictions[0]
                else:
                    return votes[0][0]

            test_model = model_aggregation.ModelAggregation(x_col='preprocessed_text', y_col='y_col', level_save="HIGH",
                                                            list_models=list_models, using_proba=False, aggregation_function=function_test,
                                                            multi_label=False, model_name=model_name, model_dir=model_dir)
            # Test it
            test.main(filename='multi_class_mono_label_train_preprocess_P1.csv', x_col='preprocessed_text', y_col=['y_col'],
                      filename_valid='multi_class_mono_label_train_preprocess_P1.csv', model=test_model)
            test_model_mono_output_regression(self, test_model)
            remove_dir(model_dir)
            remove_dir(model_dir_sgd1)
            remove_dir(model_dir_sgd2)
            remove_dir(model_dir_gbt)

        except Exception:
            self.fail('testModel_Aggregation failed')


if __name__ == '__main__':
    # Change directory to script directory parent
    abspath = os.path.abspath(__file__)
    dname = os.path.dirname(abspath)
    parentname = str(Path(dname).parent)
    os.chdir(parentname)
    # Manage venv
    full_path_lib = os.path.abspath(os.path.join(os.getcwd(), 'test_template_num'))
    if os.name == 'nt':
        is_windows = True
        # Windows: activate the virtual environment & continue with the other processes
        activate_venv = f"cd {full_path_lib}/venv_test_template_num/Scripts & activate & "
    else:
        is_windows = False
        # UNIX : We can't use "source" so we directly call python/pip from the bin of the virtual environment
        activate_venv = f"{full_path_lib}/venv_test_template_num/bin/"
    # Start tests
    unittest.main()
