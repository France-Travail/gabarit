{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template VISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites:**\n",
    "\n",
    "- This notebook must have been generated using the Gabarit's numerical template.\n",
    "\n",
    "\n",
    "- **Launch this notebook with a kernel using your project virtual environment**. In order to create a kernel linked to your virtual environment : `pip install ipykernel` and then `python -m ipykernel install --user --name=your_venv_name` (once your virtual environment is activated). Obviously, the project must be installed on this virtual environment\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How this template works\n",
    "\n",
    "### Why use gabarit's vision template ?\n",
    "\n",
    "The vision template automatically generates a project folder and python code containing mainstream models and facilitating their industrialization.\n",
    "\n",
    "The generated project can be used for **image classification** and **object detection** tasks. Of course, you have to adapt it to your particular use case. \n",
    "\n",
    "### Structure of the generated project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: monospace; display: grid; grid-template-columns: 1fr 2fr;\">\n",
    "  <div>.                                </div>  <div style=\"color: green;\"></div>\n",
    "  <div>.                                </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── {{package_name}}             </div>  <div style=\"color: green;\"># The package</div>\n",
    "  <div>│ ├── models_training            </div>  <div style=\"color: green;\"># Folder containing all the modules related to the models</div>\n",
    "  <div>│ ├── monitoring                 </div>  <div style=\"color: green;\"># Folder containing all the modules related to the explainers and MLflow</div>\n",
    "  <div>│ └── preprocessing              </div>  <div style=\"color: green;\"># Folder containing all the modules related to the preprocessing</div>\n",
    "  <div>├── {{package_name}}-data        </div>  <div style=\"color: green;\"># Folder containing all the data (datasets, embeddings, etc.)</div>\n",
    "  <div>├── {{package_name}}-exploration </div>  <div style=\"color: green;\"># Folder where all your experiments and explorations must go</div>\n",
    "  <div>├── {{package_name}}-models      </div>  <div style=\"color: green;\"># Folder containing all the generated models</div>\n",
    "  <div>├── {{package_name}}-ressources  </div>  <div style=\"color: green;\"># Folder containing some ressources such as the instructions to upload a model</div>\n",
    "  <div>├── {{package_name}}-scripts     </div>  <div style=\"color: green;\"># Folder containing examples script to preprocess data, train models, predict and use a demonstrator</div>\n",
    "  <div>│ └── utils                      </div>  <div style=\"color: green;\"># Folder containing utils scripts (such as split train/test, sampling, etc...)</div>\n",
    "  <div>├── {{package_name}}-transformers </div>  <div style=\"color: green;\"># Folder containing pytorch transformers</div>\n",
    "  <div>├── {{package_name}}-tutorials    </div>  <div style=\"color: green;\"># Folder containing notebook tutorials, including this one</div>\n",
    "  <div>├── tests                        </div>  <div style=\"color: green;\"># Folder containing all the unit tests</div>\n",
    "  <div>├── .gitignore                   </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── .coveragerc                  </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── Makefile                     </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── nose_setup_coverage.cfg      </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── README.md                    </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── requirements.txt             </div>  <div style=\"color: green;\"></div>\n",
    "  <div>├── setup.py                     </div>  <div style=\"color: green;\"></div>\n",
    "  <div>└── version.txt                  </div>  <div style=\"color: green;\"></div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General principles on the generated packages**\n",
    "\n",
    "- Data must be saved in the `{{package_name}}-data` folder<br>\n",
    "<br>\n",
    "- Trained models will automatically be saved in the `{{package_name}}-models` folder<br>\n",
    "<br>\n",
    "- Be aware that all the functions/methods for writing/reading files uses these two folders as base. Thus when a script has an argument for the path of a file/model, the given path should be **relative** to the `{{package_name}}-data` / `{{package_name}}-models` folders.<br>\n",
    "<br>\n",
    "- The provided scripts in `{{package_name}}-scripts` are given as example. You can use them as accelerators, but their use is not required.<br>\n",
    "<br>\n",
    "- You can use this package for image classification and object detection<br>\n",
    "<br>\n",
    "- The modelling part is structured as follows :\n",
    "    - `ModelClass`: main class taking care of saving data and metrics (among other)\n",
    "    - `ModelKeras`: child class of ModelClass managing all models using Keras\n",
    "<br>\n",
    "<br>\n",
    "- Each task (image classification and object detection) has a mixin class (`ModelClassifierMixin` and `ModelObjectDetectorMixin`) and specific models located in corresponding subfolders.\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load utility functions\n",
    "\n",
    "Please run the following cell to load needed utility functions. These functions are only needed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import utility functions\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(''))\n",
    "from tutorial_exercices import answers, verify, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Use the template to train your first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  dataset\n",
    "\n",
    "We are going to use a [small dataset](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_v3) containing 144 images of three categories : \n",
    "\n",
    "| Birman cat                                                                                                                                             | Bombay cat                                                                                                                                             | Shiba dog                                                                                                                                               |\n",
    "|--------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| ![A picture of a birman cat](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_v3/birman/Birman_22.jpg?raw=true) | ![A picture of a bombay cat](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_v3/bombay/Bombay_45.jpg?raw=true) | ![A picture of a shiba dog](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_v3/shiba/shiba_inu_15.jpg?raw=true) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function download all dataset images in {{package_name}}-data/dataset_v3\n",
    "utils.github_download_classification_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that a new folder called `dataset_v3` is present in your `{{package_name}}-data` directory. It contains three subfolders, one for each category : `birman`, `bombay` and `shiba`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">**Exercice 1**</span> : **train / valid / test split**\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Split the main dataset in train / valid / test sets\n",
    "\n",
    "**TODO:**\n",
    "- Use the script `utils/0_split_train_valid_test.py` on `dataset_v3`\n",
    "- Use ratios train / valid / test ratio to : 0.6 / 0.2 / 0.2 (which is default ratio)\n",
    "\n",
    "**Help:**\n",
    "- The file `utils/0_split_train_valid_test.py` splits a folder in 3 :\n",
    "    - `{dataset_folder}_train`: the training dataset\n",
    "    - `{dataset_folder}_valid`: the validation dataset\n",
    "    - `{dataset_folder}_test`: the test dataset\n",
    "- You can specify the type of split : random or stratified (here, use random)\n",
    "- Reminder: the path are relatives to `{{package_name}}-data`\n",
    "- See the script helper : `python {{package_name}}-scripts/utils/0_split_train_valid_test.py --help`\n",
    "- Don't forget to activate your virtual environment ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">**Exercice 2**</span> : **random sample**\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Get a random sample of train and test sets (n=3) (we won't use it, this exercise is just here to show what can be done)\n",
    "\n",
    "**TODO:**\n",
    "- Use the script `utils/0_create_samples.py` on the directories `dataset_v3_train` and `dataset_v3_test`\n",
    "- We want samples of 3 images\n",
    "\n",
    "**Help:**\n",
    "- Use the script : `utils/0_create_samples.py`\n",
    "- To get the possible arguments of the script: `python 0_create_samples.py --help`\n",
    "- Don't forget to activate your virtual environment ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">**Exercice 3**</span> : **pre-processing**\n",
    "\n",
    "- The script `1_preprocess_data.py` applies a preprocessing pipeline **to all images of given directories**\n",
    "- The argument `--preprocessing` (or simply `-p`) is used to specify which preprocessing pipeline should be used. \n",
    "- It works as follows:\n",
    "    - In `{{package_name}}/preprocessing/preprocess.py`: \n",
    "        - There is a dictionary of functions (`pipelines_dict`): key: str -> function \n",
    "            - /!\\ Don't remove the default element 'no_preprocess': lambda x: x /!\\ \n",
    "        - There are preprocessing functions\n",
    "    - In `1_preprocess_data.py` :\n",
    "        - We retrieve the dictionary of functions from `preprocessing/preprocess.py` \n",
    "        - If a `preprocessing` argument is specified, we keep only the corresponding key from the dictionnary \n",
    "        - Otherwise, we keep all keys (except `no_preprocess`) \n",
    "        - For each entry of the dictionary, we:\n",
    "            - Get the associated preprocessing function\n",
    "            - Load images\n",
    "            - apply the preprocessing function\n",
    "            - Save the result in a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from {{package_name}}.preprocessing.preprocess import get_preprocessors_dict\n",
    "utils.display_source(get_preprocessors_dict, strip_comments=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, two pipelines are given as examples : `preprocess_convert_rgb` and `preprocess_docs`. \n",
    "\n",
    "So if `--preprocessing` is omitted, `1_preprocess_data.py` will preprocess images with each pipeline and store the results in a `<directory>_preprocess_convert_rgb` directory and a `<directory>_preprocess_docs` directory respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "- Use `preprocess_convert_rgb` on train, validation and test data\n",
    "    - This will simply convert all images in RGB mode.\n",
    "\n",
    "**TODO:**\n",
    "- Use the script `1_preprocess_data.py` to preprocess `dataset_v3_train` and `dataset_v3_valid` with `preprocess_convert_rgb`.\n",
    "\n",
    "**Help:**\n",
    "- To get the possible arguments of the script: `python 1_preprocess_data.py --help`\n",
    "- Don't forget to activate your virtual environment ...\n",
    "\n",
    "**Important:**\n",
    "\n",
    "- Do not worry about applying the pipeline to the test dataset. Our models will store the preprocessing pipelines and :\n",
    "    - The prediction script `3_predict.py` will preprocess the test dataset with the preprocessing pipeline before sending the data to the model's predict function. This is the **batch mode**.\n",
    "    - We also expose an agnostic `predict` function (in `utils_models`) to handle new data on the fly. It will preprocess it with the preprocessing pipeline before sending the data to the model's predict function. This is the **API mode**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 3 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 3 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">**Exercice 4**</span> : **Train a classifier**\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Train a classification model on preprocessed data.\n",
    "- Use default model `ModelCnnClassifier`.\n",
    "\n",
    "**TODO:**\n",
    "- Use the script `2_training_classifier.py` to train a classifier on `dataset_v3_train_preprocess_convert_rgb`\n",
    "- Use `dataset_v3_valid_preprocess_convert_rgb` as validation data (use `--directory_valid` argument)\n",
    "\n",
    "**Help:**\n",
    "- You can reduce the number of epochs in `2_training_classifier.py` to reduce training time\n",
    "- To get the possible arguments of the script: `python 2_training_classifier.py --help`\n",
    "- Don't forget to activate your virtual environment ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 4 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 4 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">**Exercice 5**</span> : **Use transfer learning to get a better model**\n",
    "\n",
    "Our previous classifier perform poorly on validation data. This is partly due to the fact that we do not have enough data to train our model. \n",
    "\n",
    "Here we are going to use transfer learning to train a better classifier : we will use a model composed of pretrained layers for feature extraction and a classfication layer on top.\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Train a `ModelTransferLearningClassifier` on preprocessed data.\n",
    "\n",
    "**TODO:**\n",
    "- Use the script `2_training_classifier.py` to train a `ModelTransferLearningClassifier` on `dataset_v3_train_preprocess_convert_rgb`\n",
    "- Use `dataset_v3_valid_preprocess_convert_rgb` as validation data (use `--directory_valid` argument)\n",
    "- **You may appreciate to reduce the number of epochs to accelerate learning (you can use 5 epochs)**\n",
    "- **You should probably turn off fine-tuning : `with_fine_tune=False` since it requires a lot of memory**. Otherwise the training may crash during fine-tunning.\n",
    "\n",
    "**Help:**\n",
    "\n",
    "- If you look at `2_training_classifier.py` you will see that `ModelTransferLearningClassifier` is commented :\n",
    "\n",
    "```python\n",
    "if model is None:\n",
    "    model = model_cnn_classifier.ModelCnnClassifier(\n",
    "        batch_size=64, epochs=100, validation_split=0.2, patience=10,\n",
    "        width=224, height=224, depth=3, color_mode='rgb',\n",
    "        in_memory=False, data_augmentation_params={}, level_save=level_save\n",
    "    )\n",
    "    # model = model_transfer_learning_classifier.ModelTransferLearningClassifier(\n",
    "    #     batch_size=64, epochs=100, validation_split=0.2, patience=10,\n",
    "    #     width=224, height=224, depth=3, color_mode='rgb', in_memory=False, \n",
    "    #     data_augmentation_params={}, with_fine_tune=True, second_epochs=99, \n",
    "    #     second_lr=1e-5, second_patience=5, level_save=level_save\n",
    "    # )\n",
    "\n",
    "```\n",
    "- You can simply comment `ModelCnnClassifier` line and uncomment `ModelTransferLearningClassifier` line\n",
    "- This model uses pretrained [EfficientNet](https://arxiv.org/abs/1905.11946) base layers + a classification head. You can easiliy modify the model class to use another base model if you want.\n",
    "- The fine tune part can be costly, hence we advise using `with_fine_tune=False` for this exercise.\n",
    "- To get the possible arguments of the script: `python 2_training_classifier.py --help`\n",
    "- Don't forget to activate your virtual environment ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 5 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 5 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_5_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this model outperforms the previous one thanks to the Transfer Learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">**Exercice 6**</span> : **Test your model on the test dataset**\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Use your `ModelTransferLearningClassifier` model to predict on the test dataset\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "- Use the script `3_predict.py` to make predictions on `dataset_v3_test`\n",
    "\n",
    "**Help:**\n",
    "\n",
    "- Use `3_predict.py -h` to see CLI helper.\n",
    "- You **DO NOT** need to preprocess the test data ! As we said above, the preprocessing pipeline is saved alongside the model, and the script will preprocess the test data before sending it to the model's predict function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 6 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 6 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## 3. Use a saved model in python\n",
    "\n",
    "In this section, we will see how to load a saved model in python for use with new data\n",
    "\n",
    "### Load a saved model\n",
    "\n",
    "First choose one of your saved models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from {{package_name}}.utils import get_models_path, get_data_path\n",
    "from {{package_name}}.models_training import utils_models\n",
    "\n",
    "DATA_PATH = Path(get_data_path())\n",
    "MODELS_PATH = Path(get_models_path())\n",
    "\n",
    "# This line list saved model in template_num-models\n",
    "saved_model_names = sorted([model.name for model in MODELS_PATH.glob(\"*/model_*\")])\n",
    "print(\"\\n\".join(saved_model_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load it with `utils_models.load_model` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = saved_model_names[-1]\n",
    "print(model_name)\n",
    "\n",
    "model, model_conf = utils_models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download examples from [wikimedia](https://commons.wikimedia.org/w/index.php?search=&title=Special:MediaSearch&go=Go&type=image) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birman_example = \"https://upload.wikimedia.org/wikipedia/commons/6/68/Birmanstrofe_2005_%28cropped%29.jpg\"\n",
    "bombay_example = \"https://upload.wikimedia.org/wikipedia/commons/5/55/Sable_Bombay_Cat_Rosie.jpg\"\n",
    "shiba_example = \"https://upload.wikimedia.org/wikipedia/commons/b/b1/Shiba-inu.jpg\"\n",
    "\n",
    "df_examples = pd.DataFrame(\n",
    "    {\n",
    "        \"file_name\": [\"birman_example.jpg\", \"bombay_example.jpg\", \"shiba_example.jpg\"],\n",
    "        \"file_class\": [\"birman\", \"bombay\", \"shiba\"],\n",
    "        \"file_url\": [birman_example, bombay_example, shiba_example], \n",
    "    }\n",
    ")\n",
    "\n",
    "df_examples[\"file_path\"] = [\n",
    "    (DATA_PATH / \"examples\" / file_name).as_posix() \n",
    "    for file_name in df_examples[\"file_name\"]\n",
    "]\n",
    "\n",
    "(DATA_PATH / \"examples\").mkdir(exist_ok=True)\n",
    "\n",
    "for example_url, example_name in zip(df_examples[\"file_url\"], df_examples[\"file_path\"]):\n",
    "    utils.download_file(example_url, example_name, overwrite=True)\n",
    "\n",
    "df_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use our model to predict classes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from PIL import Image\n",
    "from {{package_name}}.preprocessing import preprocess\n",
    "\n",
    "# Load images\n",
    "file_paths = list(df_examples['file_path'].values)\n",
    "images = [Image.open(_) for _ in file_paths]\n",
    "\n",
    "# Get preprocessing pipeline\n",
    "preprocess_str = model_conf['preprocess_str']\n",
    "preprocessor = preprocess.get_preprocessor(preprocess_str)\n",
    "\n",
    "# Preprocess images\n",
    "images_preprocessed = preprocessor(images)\n",
    "\n",
    "# We'll create a temporary folder to save preprocessed images (models need a directory as input)\n",
    "with tempfile.TemporaryDirectory(dir=utils.get_data_path()) as tmp_folder:\n",
    "    # Save images\n",
    "    images_path = []\n",
    "    for i, img in enumerate(images_preprocessed):\n",
    "        img_path = os.path.join(tmp_folder, f\"image_{i}.png\")\n",
    "        img.save(img_path, format='PNG')\n",
    "        images_path.append(img_path)\n",
    "\n",
    "    # Get predictions\n",
    "    df = pd.DataFrame({'file_path': images_path})\n",
    "    predictions1 = model.predict(df)\n",
    "\n",
    "accuracy = (predictions1 == df_examples[\"file_class\"]).sum() / predictions1.shape[0]\n",
    "\n",
    "print(predictions1)\n",
    "print(f\"Accuracy {accuracy:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is pretty good ! :)  \n",
    "But it's quite annoying to manage the preprocessing, a temporary folder, etc...   \n",
    "Hopefully, we have a function that manage all of this : `utils_models.predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on new data - using the `utils_models.predict` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to use the provided (model agnostic) `utils_models.predict` function.\n",
    "\n",
    "This function does not need the data to be preprocessed. Everything is managed inside the function, you just have to provide the dataset and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = utils_models.predict(df_examples, model, model_conf)  # Returns a list here\n",
    "\n",
    "# Verifying accuracy :\n",
    "accuracy2 = (predictions2 == df_examples[\"file_class\"]).sum() / len(predictions2)\n",
    "print(f\"Accuracy v2 : {accuracy2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try the model on images from [google image](https://www.google.fr/search?q=shiba&source=lnms&tbm=isch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## 4. Use the template for object detection \n",
    "\n",
    "In previous sections we saw how to train a model to solve classification problem thanks to the script `3_training_classifier.py`. Here we are going to see how to use `3_training_object_detector.py` script for object detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset\n",
    "\n",
    "We are going to use a [small dataset](https://github.com/OSS-Pole-Emploi/gabarit/tree/main/gabarit/template_vision/vision_data/dataset_object_detection) containing 30 pictures of fruits :\n",
    "\n",
    "| Apples                                                                                                                                                          | Bananas                                                                                                                                                           | Oranges                                                                                                                                                           |\n",
    "|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| ![A picture of apples](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_object_detection/apple_21.jpg?raw=true) | ![A picture of a banana](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_object_detection/banana_10.jpg?raw=true) | ![A picture of oranges](https://github.com/OSS-Pole-Emploi/gabarit/blob/main/gabarit/template_vision/vision_data/dataset_object_detection/orange_44.jpg?raw=true) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function download all dataset images in {{package_name}}-data/dataset_object_detection\n",
    "utils.github_download_object_detection_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that a new folder called `dataset_object_detection` is present in your `{{package_name}}-data` directory. It contains pictures of fruits and a file called `metadata_bboxes.csv` that contains the fruits' bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Exercice 7**</span> : **Preprocess, train and predict**\n",
    "\n",
    "**Goal:**\n",
    "- Use everything we have learned in the previous exercices to create a object detection model that is capable of spotting apples, bananas and oranges in a picture.\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "- Split `dataset_object_detection` into train / valid / test datasets thanks to `utils/0_split_train_valid_test.py`\n",
    "- Use `2_training_object_detector.py` to train a `ModelDetectronFasterRcnnObjectDetector` in train data.\n",
    "    - We skip the preprocessing here.\n",
    "- Make prediction on the test data thanks to `3_predict.py`\n",
    "\n",
    "**Help:**\n",
    "\n",
    "- Each script has a CLI helper.\n",
    "- **You may appreciate to reduce the number of epochs in `2_training_object_detector.py` to reduce training time**\n",
    "- Don't forget to activate your virtual environment ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 7 : Verify your answer ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.verify_exercice_7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 7 : Solution 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.answer_exercice_7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See next section to try your model in a web demonstrator ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## 5. BONUS : Start up a small web app to introduce your models 🚀 \n",
    "\n",
    "You are now ready to demonstrate how good your models work. We implemented a default ***Streamlit*** app., let's try it !\n",
    "\n",
    "```bash\n",
    "# do not forget to activate your virtual environment\n",
    "# source venv_num_template/bin/activate \n",
    "\n",
    "streamlit run {{package_name}}-scripts/4_demonstrator.py\n",
    "```\n",
    "\n",
    "It will start a Streamlit app on the default port (8501)\n",
    "\n",
    "Visit [http://localhost:8501](http://localhost:8501) to see you demonstrator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9760371ad80c94c8bda2922cae7b60f775a006dc95a823370ac4ea842608834"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
